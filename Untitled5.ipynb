{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/stanimman/Simple/blob/master/Untitled5.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "wCk8cpXkImXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193
        },
        "outputId": "9db2992b-57f2-4485-f35f-2ffad86190dd"
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!cd data\n",
        "!pip install kaggle-cli\n",
        "!kg download -u 'stanimman' -p '***' -c 'titanic'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle-cli\n",
            "  Downloading https://files.pythonhosted.org/packages/67/61/710d02460bc4367ffd1f5e71cd9c031fb278f78aa0e8e32ca9dd99a2add8/kaggle-cli-0.12.13.tar.gz\n",
            "Collecting cliff<2.9,>=2.8.0 (from kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/e8/140ad9b5826920a8b85c187095e7725b87b913fc40243aa66dd04e9d82d6/cliff-2.8.1.tar.gz (73kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 2.8MB/s \n",
            "\u001b[?25hCollecting MechanicalSoup<0.9,>=0.7.0 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2e/f63ed26b51e36efa4cc22cad18187fcb0a253f756d548c96bb931f13de98/MechanicalSoup-0.8.0-py2.py3-none-any.whl\n",
            "Collecting lxml<4.1,>=4.0.0 (from kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/b5/4c6995f8f259f0858f79460e6d277888f8498ce1c1a466dfbb24f06ba83f/lxml-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.3MB 5.6MB/s \n",
            "\u001b[?25hCollecting cssselect<1.1,>=1.0.1 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
            "Collecting configparser (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/69/c2ce7e91c89dc073eb1aa74c0621c3eefbffe8216b3f9af9d3885265c01c/configparser-3.5.0.tar.gz\n",
            "Collecting progressbar2<3.35,>=3.34.3 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/31/b984e17bcc7491c1baeda3906fe3abc14cb5cd5dbd046ab46d9fc7a2edfd/progressbar2-3.34.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4<4.7,>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from kaggle-cli) (4.6.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/5d/c196041ffdf3e34ba206db6d61d1f893a75e1f3435699ade9bd65e089a3d/pbr-4.0.4-py2.py3-none-any.whl (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 23.8MB/s \n",
            "\u001b[?25hCollecting cmd2>=0.6.7 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/17/76a4dc6ac0e0281d87387fd2cbb9cc92ece379c590d9acb7a1693e4aebd8/cmd2-0.9.1-py3-none-any.whl (70kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 24.0MB/s \n",
            "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.1 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (2.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (1.11.0)\n",
            "Collecting stevedore>=1.20.0 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/17/6b/3b7d6d08b2ab3e5ef09e01c9f7b3b590ee135f289bb94553419e40922c25/stevedore-1.28.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (3.12)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2.18.4)\n",
            "Collecting python-utils>=2.1.0 (from progressbar2<3.35,>=3.34.3->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/a0/19119d8b7c05be49baf6c593f11c432d571b70d805f2fe94c0585e55e4c8/python_utils-2.3.0-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.5.27 (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/15/f3c29b381815ae75e27589583655f4a8567721c541b8ba8cd52f76868655/pyperclip-1.6.2.tar.gz\n",
            "Collecting colorama (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli) (0.1.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2.6)\n",
            "Building wheels for collected packages: kaggle-cli, cliff, configparser, PrettyTable, pyperclip\n",
            "  Running setup.py bdist_wheel for kaggle-cli ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d5/bb/10/c1dd1b08c7433c943cb55c46367ae3f891415e8a37300ff8a7\n",
            "  Running setup.py bdist_wheel for cliff ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/50/00/6d/d4aeb5ccdd47dd76800592b26f943e4959bc705b2d4e6e54e1\n",
            "  Running setup.py bdist_wheel for configparser ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/a3/61/79/424ef897a2f3b14684a7de5d89e8600b460b89663e6ce9d17c\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Running setup.py bdist_wheel for PrettyTable ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Running setup.py bdist_wheel for pyperclip ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/58/32/92/2227fba72f0702e4168f084c6dfc2d6d3fd1904634ab61ca6a\n",
            "Successfully built kaggle-cli cliff configparser PrettyTable pyperclip\n",
            "Installing collected packages: pbr, pyperclip, colorama, cmd2, PrettyTable, stevedore, cliff, MechanicalSoup, lxml, cssselect, configparser, python-utils, progressbar2, kaggle-cli\n",
            "Successfully installed MechanicalSoup-0.8.0 PrettyTable-0.7.2 cliff-2.8.1 cmd2-0.9.1 colorama-0.3.9 configparser-3.5.0 cssselect-1.0.3 kaggle-cli-0.12.13 lxml-4.0.0 pbr-4.0.4 progressbar2-3.34.3 pyperclip-1.6.2 python-utils-2.3.0 stevedore-1.28.0\n",
            "downloading https://www.kaggle.com/c/titanic/download/train.csv\n",
            "\n",
            "train.csv 100% |####################################| Time: 0:00:01  58.0 KiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/titanic/download/test.csv\n",
            "\n",
            "test.csv 100% |#####################################| Time: 0:00:00 136.6 KiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/titanic/download/gender_submission.csv\n",
            "\n",
            "gender_submission.csv 100% |########################| Time: 0:00:00  13.2 KiB/s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yyHvbuRdLnhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ec4e99e3-2ef7-43d4-c975-c7bc202f9e9c"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install  -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jdLyZB1NI7Gg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# numpy and pandas for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "# sklearn preprocessing for dealing with categorical variables\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# File system manangement\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g-W9F_n-I4Bp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "titanic_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Ws_SdtaJCX7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
        "titanic_df = titanic_df.drop(['PassengerId','Name','Ticket'], axis=1)\n",
        "test_df    = test_df.drop(['Name','Ticket'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZ3QrjsRJE-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "d7cf84dc-871e-4474-b198-2456c97ac4cc"
      },
      "cell_type": "code",
      "source": [
        "# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n",
        "titanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(\"S\")\n",
        "# Fare\n",
        "\n",
        "# only for test_df, since there is a missing \"Fare\" values\n",
        "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n",
        "\n",
        "# convert from float to int\n",
        "titanic_df['Fare'] = titanic_df['Fare'].astype(int)\n",
        "test_df['Fare']    = test_df['Fare'].astype(int)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "# Age \n",
        "\n",
        "fig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n",
        "axis1.set_title('Original Age values - Titanic')\n",
        "axis2.set_title('New Age values - Titanic')\n",
        "\n",
        "# axis3.set_title('Original Age values - Test')\n",
        "# axis4.set_title('New Age values - Test')\n",
        "\n",
        "# get average, std, and number of NaN values in titanic_df\n",
        "average_age_titanic   = titanic_df[\"Age\"].mean()\n",
        "std_age_titanic       = titanic_df[\"Age\"].std()\n",
        "count_nan_age_titanic = titanic_df[\"Age\"].isnull().sum()\n",
        "\n",
        "# get average, std, and number of NaN values in test_df\n",
        "average_age_test   = test_df[\"Age\"].mean()\n",
        "std_age_test       = test_df[\"Age\"].std()\n",
        "count_nan_age_test = test_df[\"Age\"].isnull().sum()\n",
        "\n",
        "# generate random numbers between (mean - std) & (mean + std)\n",
        "rand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\n",
        "rand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n",
        "\n",
        "# plot original Age values\n",
        "# NOTE: drop all null values, and convert to int\n",
        "titanic_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n",
        "# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n",
        "\n",
        "# fill NaN values in Age column with random values generated\n",
        "titanic_df[\"Age\"][np.isnan(titanic_df[\"Age\"])] = rand_1\n",
        "test_df[\"Age\"][np.isnan(test_df[\"Age\"])] = rand_2\n",
        "\n",
        "# convert from float to int\n",
        "titanic_df['Age'] = titanic_df['Age'].astype(int)\n",
        "test_df['Age']    = test_df['Age'].astype(int)\n",
        "        \n",
        "# plot new Age Values\n",
        "titanic_df['Age'].hist(bins=70, ax=axis2)\n",
        "\n",
        "# Cabin\n",
        "# It has a lot of NaN values, so it won't cause a remarkable impact on prediction\n",
        "titanic_df.drop(\"Cabin\",axis=1,inplace=True)\n",
        "test_df.drop(\"Cabin\",axis=1,inplace=True)\n",
        "\n",
        "# Family\n",
        "\n",
        "# Instead of having two columns Parch & SibSp, \n",
        "# we can have only one column represent if the passenger had any family member aboard or not,\n",
        "# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\n",
        "titanic_df['Family'] =  titanic_df[\"Parch\"] + titanic_df[\"SibSp\"]\n",
        "titanic_df['Family'].loc[titanic_df['Family'] > 0] = 1\n",
        "titanic_df['Family'].loc[titanic_df['Family'] == 0] = 0\n",
        "\n",
        "test_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\n",
        "test_df['Family'].loc[test_df['Family'] > 0] = 1\n",
        "test_df['Family'].loc[test_df['Family'] == 0] = 0\n",
        "\n",
        "# drop Parch & SibSp\n",
        "titanic_df = titanic_df.drop(['SibSp','Parch'], axis=1)\n",
        "test_df    = test_df.drop(['SibSp','Parch'], axis=1)\n",
        "\n",
        "# Sex\n",
        "\n",
        "# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n",
        "# So, we can classify passengers as males, females, and child\n",
        "def get_person(passenger):\n",
        "    age,sex = passenger\n",
        "    return 'child' if age < 16 else sex\n",
        "    \n",
        "titanic_df['Person'] = titanic_df[['Age','Sex']].apply(get_person,axis=1)\n",
        "test_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n",
        "\n",
        "# No need to use Sex column since we created Person column\n",
        "titanic_df.drop(['Sex'],axis=1,inplace=True)\n",
        "test_df.drop(['Sex'],axis=1,inplace=True)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2UAAAEHCAYAAAAu1e4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe26977ce48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DctxPGcIJbPa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define training and testing sets\n",
        "\n",
        "X_train = titanic_df.drop(\"Survived\",axis=1)\n",
        "Y_train = titanic_df[\"Survived\"]\n",
        "X_test  = test_df.drop(\"PassengerId\",axis=1).copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5iGdmHbjJi6d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def label_encoding(app_train):\n",
        "  # Create a label encoder object\n",
        "  le = LabelEncoder()\n",
        "  le_count = 0\n",
        "\n",
        "  # Iterate through the columns\n",
        "  for col in app_train:\n",
        "      #if app_train[col].dtype == 'object':\n",
        "          # If 2 or fewer unique categories\n",
        "          if len(list(app_train[col].unique())):\n",
        "              # Train on the training data\n",
        "              le.fit(app_train[col])\n",
        "              # Transform both training and testing data\n",
        "              app_train[col] = le.transform(app_train[col])\n",
        "              \n",
        "              # Keep track of how many columns were label encoded\n",
        "              le_count += 1\n",
        "\n",
        "  print('%d columns were label encoded.' % le_count)\n",
        "  return app_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y7xlhqjsJtjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3805dcd6-20b7-44e2-f667-a8a8ef4802c0"
      },
      "cell_type": "code",
      "source": [
        "X_train_nn = label_encoding(X_train)\n",
        "Y_train_nn = Y_train\n",
        "X_test_nn = label_encoding(X_test)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 columns were label encoded.\n",
            "6 columns were label encoded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6cvaZtQXJ-Ng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c2c00c0c-20f4-4e44-a976-cf1f6916bfaa"
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5cd16000 @  0x7fd452c631c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\r\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rsaFOgH4J86_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ujcbga5qKIbH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb_sz = []\n",
        "emb_sz = [len(list(X_train_nn[col].unique())) for col in X_train_nn]\n",
        "emb_szs = [(c, min(50, c)) for c in emb_sz]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jGYjzBYYKYAN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize weight of Embedding matrix\n",
        "def emb_init(x):\n",
        "    x = x.weight.data\n",
        "    sc = 2/(x.size(1)+1)\n",
        "    x.uniform_(-sc,sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eo5sU_fcKZEm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet_Embed(nn.Module):\n",
        "    def __init__(self, input_size,emb_szs,hidden_size, num_classes):\n",
        "        super(NeuralNet_Embed, self).__init__()\n",
        "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
        "        for emb in self.embs: emb_init(emb)\n",
        "        #self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, input_cat):\n",
        "        x_torch = [e(input_cat[:,i]) for i,e in enumerate(self.embs)]\n",
        "        x = torch.cat(x_torch, 1)\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pCTvJhmYNaY8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_size = 111\n",
        "hidden_size =250\n",
        "num_classes =2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Nd9ebEFKfXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = NeuralNet_Embed(input_size, emb_szs,hidden_size, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HsNgUjIcOHGl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pOsvgwjCKL54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "# nn.CrossEntropyLoss() computes softmax internally \n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SxI5B11HON0r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_torch_label = torch.from_numpy(Y_train_nn.values)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s51ovSWxPGcY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "df_tensor = torch.from_numpy(X_train_nn.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T0vCXOEPPtZh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_tensor = torch.from_numpy(Y_train_nn.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nPjnJIgniXtE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "samp_size = 891\n",
        "train_ratio = 0.75\n",
        "# train_ratio = 0.9\n",
        "train_size = int(samp_size * train_ratio); train_size\n",
        "val_idx = list(range(train_size, 891))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HZvbcG3pkXQL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_tensor = torch.from_numpy(X_train_nn.values[0:668,])\n",
        "y_train_tensor = torch.from_numpy(Y_train_nn.values[0:668])\n",
        "print(df_train_tensor.shape)\n",
        "print(y_train_tensor.shape)\n",
        "print(df_train_tensor[667])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z0f6v6TWi6xz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9ce58e22-1019-4717-df6e-10b2896dcdaf"
      },
      "cell_type": "code",
      "source": [
        "df_val_tensor = torch.from_numpy(X_train_nn.values[val_idx])\n",
        "y_val_tensor = torch.from_numpy(Y_train_nn.values[val_idx])\n",
        "print(y_val_tensor[0])\n",
        "print(df_val_tensor[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0)\n",
            "tensor([  2,  43,   5,   2,   0,   2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "spBw7YJ9j8_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e1c76c82-6660-4735-fd5b-e02b9f58c36d"
      },
      "cell_type": "code",
      "source": [
        "print(df_val_tensor.shape)\n",
        "print(y_val_tensor.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([223, 6])\n",
            "torch.Size([223])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9DFclPZgiZvb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xCNkI7CeOTDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "943f1bec-004b-428b-b1fc-1117d5d2c779"
      },
      "cell_type": "code",
      "source": [
        "#previous_val_loss = -9999\n",
        "for epoch in range(10000):\n",
        "  # Forward_pass\n",
        "  \n",
        "  pred = model(df_train_tensor) # give the data to calculate forward linear layer\n",
        "  val_pred = model(df_val_tensor)\n",
        "  loss = criterion(pred,y_train_tensor) # compare prediction vs actuals\n",
        "  val_loss =  criterion(val_pred,y_val_tensor)\n",
        "  if (epoch + 1) % 100 == 0 :\n",
        "    print ('Epoch : loss ' , epoch, loss.item(),'    Epoch : Val_loss ' , epoch, val_loss.item())\n",
        "    \n",
        "  # Make gradient to be zero\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Backward pass  Auto differntiation not much of an worry\n",
        "  loss.backward()\n",
        "\n",
        "  #Update using optimizer after calculating loss\n",
        "  optimizer.step()\n",
        "  #if (previous_val_loss > val_loss):\n",
        "  #  break\n",
        "  #previous_val_loss = val_loss\n",
        "  "
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : loss  99 0.6639445424079895     Epoch : Val_loss  99 0.6567284464836121\n",
            "Epoch : loss  199 0.655430257320404     Epoch : Val_loss  199 0.6453473567962646\n",
            "Epoch : loss  299 0.6482595205307007     Epoch : Val_loss  299 0.6365371942520142\n",
            "Epoch : loss  399 0.6401246786117554     Epoch : Val_loss  399 0.6272527575492859\n",
            "Epoch : loss  499 0.6300672888755798     Epoch : Val_loss  499 0.6162212491035461\n",
            "Epoch : loss  599 0.6172152161598206     Epoch : Val_loss  599 0.6025363802909851\n",
            "Epoch : loss  699 0.6006925702095032     Epoch : Val_loss  699 0.5853637456893921\n",
            "Epoch : loss  799 0.5801849961280823     Epoch : Val_loss  799 0.5645577907562256\n",
            "Epoch : loss  899 0.5566134452819824     Epoch : Val_loss  899 0.5411035418510437\n",
            "Epoch : loss  999 0.5323524475097656     Epoch : Val_loss  999 0.5173225998878479\n",
            "Epoch : loss  1099 0.5105791687965393     Epoch : Val_loss  1099 0.49616292119026184\n",
            "Epoch : loss  1199 0.4936845600605011     Epoch : Val_loss  1199 0.47969457507133484\n",
            "Epoch : loss  1299 0.48182839155197144     Epoch : Val_loss  1299 0.46791496872901917\n",
            "Epoch : loss  1399 0.47365593910217285     Epoch : Val_loss  1399 0.4594937562942505\n",
            "Epoch : loss  1499 0.4677172005176544     Epoch : Val_loss  1499 0.4530530273914337\n",
            "Epoch : loss  1599 0.4630514681339264     Epoch : Val_loss  1599 0.44774025678634644\n",
            "Epoch : loss  1699 0.45914915204048157     Epoch : Val_loss  1699 0.44310376048088074\n",
            "Epoch : loss  1799 0.4557036757469177     Epoch : Val_loss  1799 0.43890371918678284\n",
            "Epoch : loss  1899 0.4526141583919525     Epoch : Val_loss  1899 0.4350750744342804\n",
            "Epoch : loss  1999 0.44978949427604675     Epoch : Val_loss  1999 0.4315798878669739\n",
            "Epoch : loss  2099 0.44712769985198975     Epoch : Val_loss  2099 0.42833954095840454\n",
            "Epoch : loss  2199 0.4446147084236145     Epoch : Val_loss  2199 0.4253133237361908\n",
            "Epoch : loss  2299 0.4422336518764496     Epoch : Val_loss  2299 0.4225424826145172\n",
            "Epoch : loss  2399 0.4399716556072235     Epoch : Val_loss  2399 0.41999006271362305\n",
            "Epoch : loss  2499 0.43777528405189514     Epoch : Val_loss  2499 0.41759946942329407\n",
            "Epoch : loss  2599 0.435635507106781     Epoch : Val_loss  2599 0.4153654873371124\n",
            "Epoch : loss  2699 0.43356621265411377     Epoch : Val_loss  2699 0.4132978618144989\n",
            "Epoch : loss  2799 0.43158480525016785     Epoch : Val_loss  2799 0.4113859236240387\n",
            "Epoch : loss  2899 0.429663747549057     Epoch : Val_loss  2899 0.40964844822883606\n",
            "Epoch : loss  2999 0.4278213083744049     Epoch : Val_loss  2999 0.4080588221549988\n",
            "Epoch : loss  3099 0.42602264881134033     Epoch : Val_loss  3099 0.40660110116004944\n",
            "Epoch : loss  3199 0.4242362380027771     Epoch : Val_loss  3199 0.4052574038505554\n",
            "Epoch : loss  3299 0.42245012521743774     Epoch : Val_loss  3299 0.40401095151901245\n",
            "Epoch : loss  3399 0.42067086696624756     Epoch : Val_loss  3399 0.4028323292732239\n",
            "Epoch : loss  3499 0.41890186071395874     Epoch : Val_loss  3499 0.40172556042671204\n",
            "Epoch : loss  3599 0.4171096384525299     Epoch : Val_loss  3599 0.4006742238998413\n",
            "Epoch : loss  3699 0.4152965545654297     Epoch : Val_loss  3699 0.39968541264533997\n",
            "Epoch : loss  3799 0.4134640395641327     Epoch : Val_loss  3799 0.3987552523612976\n",
            "Epoch : loss  3899 0.41161465644836426     Epoch : Val_loss  3899 0.3978743851184845\n",
            "Epoch : loss  3999 0.40973472595214844     Epoch : Val_loss  3999 0.3970380127429962\n",
            "Epoch : loss  4099 0.4078276455402374     Epoch : Val_loss  4099 0.39624014496803284\n",
            "Epoch : loss  4199 0.4058924615383148     Epoch : Val_loss  4199 0.3954751491546631\n",
            "Epoch : loss  4299 0.4039251506328583     Epoch : Val_loss  4299 0.3947341740131378\n",
            "Epoch : loss  4399 0.40193381905555725     Epoch : Val_loss  4399 0.3940269947052002\n",
            "Epoch : loss  4499 0.39991217851638794     Epoch : Val_loss  4499 0.3933328092098236\n",
            "Epoch : loss  4599 0.397858202457428     Epoch : Val_loss  4599 0.39265674352645874\n",
            "Epoch : loss  4699 0.3957762122154236     Epoch : Val_loss  4699 0.39200323820114136\n",
            "Epoch : loss  4799 0.3936634063720703     Epoch : Val_loss  4799 0.3913669288158417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : loss  4899 0.39151960611343384     Epoch : Val_loss  4899 0.39076462388038635\n",
            "Epoch : loss  4999 0.38935327529907227     Epoch : Val_loss  4999 0.3901829719543457\n",
            "Epoch : loss  5099 0.3871663808822632     Epoch : Val_loss  5099 0.38961881399154663\n",
            "Epoch : loss  5199 0.3849572241306305     Epoch : Val_loss  5199 0.3890738785266876\n",
            "Epoch : loss  5299 0.38271552324295044     Epoch : Val_loss  5299 0.38857829570770264\n",
            "Epoch : loss  5399 0.38045018911361694     Epoch : Val_loss  5399 0.388115793466568\n",
            "Epoch : loss  5499 0.378164678812027     Epoch : Val_loss  5499 0.3876703381538391\n",
            "Epoch : loss  5599 0.3758598864078522     Epoch : Val_loss  5599 0.3872615396976471\n",
            "Epoch : loss  5699 0.3735449016094208     Epoch : Val_loss  5699 0.386880487203598\n",
            "Epoch : loss  5799 0.3712196946144104     Epoch : Val_loss  5799 0.3865267038345337\n",
            "Epoch : loss  5899 0.36888962984085083     Epoch : Val_loss  5899 0.38619548082351685\n",
            "Epoch : loss  5999 0.36655840277671814     Epoch : Val_loss  5999 0.38588064908981323\n",
            "Epoch : loss  6099 0.3642256259918213     Epoch : Val_loss  6099 0.3856153190135956\n",
            "Epoch : loss  6199 0.36188891530036926     Epoch : Val_loss  6199 0.3854098916053772\n",
            "Epoch : loss  6299 0.35956135392189026     Epoch : Val_loss  6299 0.3852494955062866\n",
            "Epoch : loss  6399 0.35724329948425293     Epoch : Val_loss  6399 0.3851153254508972\n",
            "Epoch : loss  6499 0.3549374043941498     Epoch : Val_loss  6499 0.38502857089042664\n",
            "Epoch : loss  6599 0.352651983499527     Epoch : Val_loss  6599 0.3850123882293701\n",
            "Epoch : loss  6699 0.35038772225379944     Epoch : Val_loss  6699 0.3850480914115906\n",
            "Epoch : loss  6799 0.34814292192459106     Epoch : Val_loss  6799 0.3851183354854584\n",
            "Epoch : loss  6899 0.3459223210811615     Epoch : Val_loss  6899 0.385225772857666\n",
            "Epoch : loss  6999 0.3437276780605316     Epoch : Val_loss  6999 0.38539764285087585\n",
            "Epoch : loss  7099 0.341561883687973     Epoch : Val_loss  7099 0.3856242299079895\n",
            "Epoch : loss  7199 0.33942005038261414     Epoch : Val_loss  7199 0.38589683175086975\n",
            "Epoch : loss  7299 0.33731019496917725     Epoch : Val_loss  7299 0.3862205147743225\n",
            "Epoch : loss  7399 0.33524033427238464     Epoch : Val_loss  7399 0.3865898847579956\n",
            "Epoch : loss  7499 0.3332161009311676     Epoch : Val_loss  7499 0.38700807094573975\n",
            "Epoch : loss  7599 0.33123040199279785     Epoch : Val_loss  7599 0.38747644424438477\n",
            "Epoch : loss  7699 0.3292829692363739     Epoch : Val_loss  7699 0.3879827857017517\n",
            "Epoch : loss  7799 0.32737573981285095     Epoch : Val_loss  7799 0.3885279893875122\n",
            "Epoch : loss  7899 0.3255101442337036     Epoch : Val_loss  7899 0.38912057876586914\n",
            "Epoch : loss  7999 0.32367879152297974     Epoch : Val_loss  7999 0.38975149393081665\n",
            "Epoch : loss  8099 0.32188546657562256     Epoch : Val_loss  8099 0.3904079496860504\n",
            "Epoch : loss  8199 0.320129930973053     Epoch : Val_loss  8199 0.3910864293575287\n",
            "Epoch : loss  8299 0.3184092044830322     Epoch : Val_loss  8299 0.39178985357284546\n",
            "Epoch : loss  8399 0.3167228400707245     Epoch : Val_loss  8399 0.3925139904022217\n",
            "Epoch : loss  8499 0.31507453322410583     Epoch : Val_loss  8499 0.3932517468929291\n",
            "Epoch : loss  8599 0.31346699595451355     Epoch : Val_loss  8599 0.39399608969688416\n",
            "Epoch : loss  8699 0.3118944764137268     Epoch : Val_loss  8699 0.3947657644748688\n",
            "Epoch : loss  8799 0.31035733222961426     Epoch : Val_loss  8799 0.39554688334465027\n",
            "Epoch : loss  8899 0.3088543713092804     Epoch : Val_loss  8899 0.3963448107242584\n",
            "Epoch : loss  8999 0.30738314986228943     Epoch : Val_loss  8999 0.39714229106903076\n",
            "Epoch : loss  9099 0.30594402551651     Epoch : Val_loss  9099 0.3979419767856598\n",
            "Epoch : loss  9199 0.30453747510910034     Epoch : Val_loss  9199 0.398744136095047\n",
            "Epoch : loss  9299 0.3031611740589142     Epoch : Val_loss  9299 0.39955294132232666\n",
            "Epoch : loss  9399 0.30181384086608887     Epoch : Val_loss  9399 0.4003610908985138\n",
            "Epoch : loss  9499 0.30049657821655273     Epoch : Val_loss  9499 0.40116816759109497\n",
            "Epoch : loss  9599 0.29920998215675354     Epoch : Val_loss  9599 0.401969313621521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : loss  9699 0.2979530990123749     Epoch : Val_loss  9699 0.40277987718582153\n",
            "Epoch : loss  9799 0.2967187166213989     Epoch : Val_loss  9799 0.40358713269233704\n",
            "Epoch : loss  9899 0.29551243782043457     Epoch : Val_loss  9899 0.4043930470943451\n",
            "Epoch : loss  9999 0.29433032870292664     Epoch : Val_loss  9999 0.4051998257637024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_u6FBgwUPX0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceaac48e-6d9e-4076-85be-a5b494623d00"
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 223\n",
        "    outputs = model(df_val_tensor)\n",
        "    for i in range(len(y_val_tensor)):\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += (predicted[i] == y_val_tensor[i].type(torch.LongTensor)).sum()\n",
        "      \n",
        "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images: 83 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "259m1ZK6rS0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "test_torch_label = torch.from_numpy(X_test_nn.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aXZi7nR9r48F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 223\n",
        "    outputs = model(test_torch_label)\n",
        "    for i in range(test_torch_label.shape[0]):\n",
        "      _, predicted_test = torch.max(outputs.data, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5EF4LQLttGJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = predicted_test.data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KX7TT_rQuCKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "3557c5a0-f0df-44f0-db5e-adc6f8040978"
      },
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "ltaCK5wjr6sS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e058ee87-add6-4c9e-c9c8-dc8300abdd33"
      },
      "cell_type": "code",
      "source": [
        "# Make a submission dataframe\n",
        "submit = test_df[['PassengerId']]\n",
        "submit['Survived'] = predictions\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "caJBYzBStziq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "a9f40bfe-c102-43be-89c4-b1cd28784630"
      },
      "cell_type": "code",
      "source": [
        "submit.head(2)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived\n",
              "0          892         0\n",
              "1          893         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "metadata": {
        "id": "4dp3wfGet1ot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submit.to_csv('titanic.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_lt9JLvPwbRs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('titanic.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}