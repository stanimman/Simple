{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog_Breed_Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stanimman/Simple/blob/master/Dog_Breed_Dataset_Fastai_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2kfs36vfUK8W",
        "colab_type": "code",
        "outputId": "29473939-4451-490c-841d-9eedfeb89d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5bcea000 @  0x7f32f1cbe2a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uM9W5gX3WAJr",
        "colab_type": "code",
        "outputId": "374c65cc-382a-4bda-9872-bdda9f262958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!pip uninstall Pillow -y\n",
        "\n",
        "!pip install Pillow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-5.3.0:\n",
            "  Successfully uninstalled Pillow-5.3.0\n",
            "Collecting Pillow\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: Pillow\n",
            "Successfully installed Pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AE_TWJD2AVkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d829a41-d1e1-477f-b3e9-0bdc4abc9ffd"
      },
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M6Prx0t6AjWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1397
        },
        "outputId": "b3ef9471-9b1e-45ca-b49c-12b10793924b"
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle-cli\n",
        "!kg download -u 'stanimman' -p 'Legspinner@1' -c 'dog-breed-identification'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle-cli\n",
            "  Downloading https://files.pythonhosted.org/packages/67/61/710d02460bc4367ffd1f5e71cd9c031fb278f78aa0e8e32ca9dd99a2add8/kaggle-cli-0.12.13.tar.gz\n",
            "Collecting cliff<2.9,>=2.8.0 (from kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/ba/f45621f885ecd8527142811c279740367eb6c552ceb8debfdb7c5fca0677/cliff-2.8.2.tar.gz (72kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 6.7MB/s \n",
            "\u001b[?25hCollecting MechanicalSoup<0.9,>=0.7.0 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2e/f63ed26b51e36efa4cc22cad18187fcb0a253f756d548c96bb931f13de98/MechanicalSoup-0.8.0-py2.py3-none-any.whl\n",
            "Collecting lxml<4.1,>=4.0.0 (from kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/b5/4c6995f8f259f0858f79460e6d277888f8498ce1c1a466dfbb24f06ba83f/lxml-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.3MB 5.8MB/s \n",
            "\u001b[?25hCollecting cssselect<1.1,>=1.0.1 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
            "Collecting configparser (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/69/c2ce7e91c89dc073eb1aa74c0621c3eefbffe8216b3f9af9d3885265c01c/configparser-3.5.0.tar.gz\n",
            "Collecting progressbar2<3.35,>=3.34.3 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/31/b984e17bcc7491c1baeda3906fe3abc14cb5cd5dbd046ab46d9fc7a2edfd/progressbar2-3.34.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4<4.7,>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from kaggle-cli) (4.6.3)\n",
            "Collecting pbr!=2.1.0,>=2.0.0 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/04/fddc1c2dd75b256eda4d360024692231a2c19a0c61ad7f4a162407c1ab58/pbr-5.1.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 26.3MB/s \n",
            "\u001b[?25hCollecting cmd2>=0.6.7 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/21/bcad9e336ca318614d52b25375f20286e6a6522e30ec2422be520f6ebedd/cmd2-0.9.6-py3-none-any.whl (86kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 23.9MB/s \n",
            "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.1 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (2.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (1.11.0)\n",
            "Collecting stevedore>=1.20.0 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/fa/8683fab2a6e15ecfe107996e56fab91e52fe3ec0b40ca9440a0e1ffe6892/stevedore-1.30.0-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 20.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (3.13)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2.18.4)\n",
            "Collecting python-utils>=2.1.0 (from progressbar2<3.35,>=3.34.3->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/a0/19119d8b7c05be49baf6c593f11c432d571b70d805f2fe94c0585e55e4c8/python_utils-2.3.0-py2.py3-none-any.whl\n",
            "Collecting attrs>=16.3.0 (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/3a/e1/5f9023cc983f1a628a8c2fd051ad19e76ff7b142a0faf329336f9a62a514/attrs-18.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli) (0.1.7)\n",
            "Collecting pyperclip>=1.5.27 (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/0f/4eda562dffd085945d57c2d9a5da745cfb5228c02bc90f2c74bbac746243/pyperclip-1.7.0.tar.gz\n",
            "Collecting colorama (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/93/6e8289231675d561d476d656c2ee3a868c1cca207e16c118d4503b25e2bf/colorama-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (3.0.4)\n",
            "Building wheels for collected packages: kaggle-cli, cliff, configparser, PrettyTable, pyperclip\n",
            "  Running setup.py bdist_wheel for kaggle-cli ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d5/bb/10/c1dd1b08c7433c943cb55c46367ae3f891415e8a37300ff8a7\n",
            "  Running setup.py bdist_wheel for cliff ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/02/22/09/66f8c243f9c68dee7e6456a0fd6c117439a64394fdaf02d965\n",
            "  Running setup.py bdist_wheel for configparser ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a3/61/79/424ef897a2f3b14684a7de5d89e8600b460b89663e6ce9d17c\n",
            "  Running setup.py bdist_wheel for PrettyTable ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Running setup.py bdist_wheel for pyperclip ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/92/f0/ac/2ba2972034e98971c3654ece337ac61e546bdeb34ca960dc8c\n",
            "Successfully built kaggle-cli cliff configparser PrettyTable pyperclip\n",
            "Installing collected packages: pbr, attrs, pyperclip, colorama, cmd2, PrettyTable, stevedore, cliff, MechanicalSoup, lxml, cssselect, configparser, python-utils, progressbar2, kaggle-cli\n",
            "Successfully installed MechanicalSoup-0.8.0 PrettyTable-0.7.2 attrs-18.2.0 cliff-2.8.2 cmd2-0.9.6 colorama-0.4.0 configparser-3.5.0 cssselect-1.0.3 kaggle-cli-0.12.13 lxml-4.0.0 pbr-5.1.1 progressbar2-3.34.3 pyperclip-1.7.0 python-utils-2.3.0 stevedore-1.30.0\n",
            "/usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py:37: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 37 of the file /usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  response.content, **soup_config)\n",
            "downloading https://www.kaggle.com/c/dog-breed-identification/download/labels.csv.zip\n",
            "\n",
            "labels.csv.zip 100% |################################| Time: 0:00:00 578.6 KiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/dog-breed-identification/download/sample_submission.csv.zip\n",
            "\n",
            "sample_submission.csv.zip 100% |#####################| Time: 0:00:00 480.8 KiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/dog-breed-identification/download/test.zip\n",
            "\n",
            "test.zip 100% |######################################| Time: 0:00:11  29.5 MiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/dog-breed-identification/download/train.zip\n",
            "\n",
            "train.zip 100% |#####################################| Time: 0:00:12  26.6 MiB/s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DNHzKBM4BHqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53d0c3f4-58e8-4697-edc6-f4f78d392336"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GT5zssp8UoT-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip -q labels.csv.zip\n",
        "!unzip -q train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hu1HNJI9UrrX",
        "colab_type": "code",
        "outputId": "7332c925-d4f8-4152-bcd3-69f49ed2230a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip sample_submission.csv.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uXVQKTvBWYDf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%matplotlib inline\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oqoUXOimVr93",
        "colab_type": "code",
        "outputId": "ee63322d-fad7-4753-9d09-de6c66478ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "INPUT_SIZE = 224\n",
        "NUM_CLASSES = 120\n",
        "data_dir = '/content'\n",
        "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
        "sample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\n",
        "print(len(listdir(join(data_dir, 'train'))), len(labels))\n",
        "#print(len(listdir(join(data_dir, 'test'))), len(sample_submission))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10222 10222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KLZHr_K9Wwle",
        "colab_type": "code",
        "outputId": "f2dc55ae-8c8e-41a5-9153-a6b4c70984f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n",
        "labels = labels[labels['breed'].isin(selected_breed_list)]\n",
        "labels['target'] = 1\n",
        "labels['rank'] = labels.groupby('breed').rank()['id']\n",
        "labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
        "\n",
        "train = labels_pivot.sample(frac=0.8)\n",
        "valid = labels_pivot[~labels_pivot['id'].isin(train['id'])]\n",
        "print(train.shape, valid.shape) # The shape is 121 because 120 class + Id (Column)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8178, 121) (2044, 121)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NVChCUMmcDM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "eefdc7f6-3742-47a4-ad16-7e68ae703c14"
      },
      "cell_type": "code",
      "source": [
        "valid.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>breed</th>\n",
              "      <th>id</th>\n",
              "      <th>affenpinscher</th>\n",
              "      <th>afghan_hound</th>\n",
              "      <th>african_hunting_dog</th>\n",
              "      <th>airedale</th>\n",
              "      <th>american_staffordshire_terrier</th>\n",
              "      <th>appenzeller</th>\n",
              "      <th>australian_terrier</th>\n",
              "      <th>basenji</th>\n",
              "      <th>basset</th>\n",
              "      <th>...</th>\n",
              "      <th>toy_poodle</th>\n",
              "      <th>toy_terrier</th>\n",
              "      <th>vizsla</th>\n",
              "      <th>walker_hound</th>\n",
              "      <th>weimaraner</th>\n",
              "      <th>welsh_springer_spaniel</th>\n",
              "      <th>west_highland_white_terrier</th>\n",
              "      <th>whippet</th>\n",
              "      <th>wire-haired_fox_terrier</th>\n",
              "      <th>yorkshire_terrier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>002211c81b498ef88e1b40b9abf84e1d</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00290d3e1fdd27226ba27a8ce248ce85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>00693b8bc2470375cc744a6391d397ec</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>007ff9a78eba2aebb558afea3a51c469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>00a862390341c5be090dd72bd2bc19ef</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "breed                                id  affenpinscher  afghan_hound  \\\n",
              "5      002211c81b498ef88e1b40b9abf84e1d            0.0           0.0   \n",
              "6      00290d3e1fdd27226ba27a8ce248ce85            0.0           0.0   \n",
              "12     00693b8bc2470375cc744a6391d397ec            0.0           0.0   \n",
              "18     007ff9a78eba2aebb558afea3a51c469            0.0           0.0   \n",
              "26     00a862390341c5be090dd72bd2bc19ef            0.0           0.0   \n",
              "\n",
              "breed  african_hunting_dog  airedale  american_staffordshire_terrier  \\\n",
              "5                      0.0       0.0                             0.0   \n",
              "6                      0.0       0.0                             0.0   \n",
              "12                     0.0       0.0                             0.0   \n",
              "18                     0.0       0.0                             0.0   \n",
              "26                     0.0       0.0                             0.0   \n",
              "\n",
              "breed  appenzeller  australian_terrier  basenji  basset        ...          \\\n",
              "5              0.0                 0.0      0.0     0.0        ...           \n",
              "6              0.0                 0.0      0.0     0.0        ...           \n",
              "12             0.0                 0.0      0.0     0.0        ...           \n",
              "18             0.0                 0.0      0.0     0.0        ...           \n",
              "26             0.0                 0.0      0.0     0.0        ...           \n",
              "\n",
              "breed  toy_poodle  toy_terrier  vizsla  walker_hound  weimaraner  \\\n",
              "5             0.0          0.0     0.0           0.0         0.0   \n",
              "6             0.0          0.0     0.0           0.0         0.0   \n",
              "12            0.0          0.0     0.0           0.0         0.0   \n",
              "18            0.0          0.0     0.0           0.0         0.0   \n",
              "26            0.0          0.0     0.0           0.0         0.0   \n",
              "\n",
              "breed  welsh_springer_spaniel  west_highland_white_terrier  whippet  \\\n",
              "5                         0.0                          0.0      0.0   \n",
              "6                         0.0                          0.0      0.0   \n",
              "12                        0.0                          0.0      0.0   \n",
              "18                        0.0                          0.0      0.0   \n",
              "26                        0.0                          0.0      0.0   \n",
              "\n",
              "breed  wire-haired_fox_terrier  yorkshire_terrier  \n",
              "5                          0.0                0.0  \n",
              "6                          0.0                0.0  \n",
              "12                         0.0                0.0  \n",
              "18                         0.0                0.0  \n",
              "26                         0.0                0.0  \n",
              "\n",
              "[5 rows x 121 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "TlsHnL5OYOib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69236e6f-25ea-4e46-c4c2-4068210b5207"
      },
      "cell_type": "code",
      "source": [
        "mat = valid.iloc[:,1:].as_matrix().astype('float')\n",
        "classes = np.argmax(mat, axis=1)\n",
        "len(classes)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2044"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "0azF1o3xcziU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f442c41-f855-465a-8e2c-2c73bb5bd9a5"
      },
      "cell_type": "code",
      "source": [
        "class_element = np.bincount(classes)\n",
        "len(class_element)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "_Jl7Oh56W_Df",
        "colab_type": "code",
        "outputId": "99f0f15f-c56e-4609-d5b7-17956e61316c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(train.iloc[0].unique())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bd6927dadc87d3e7c5beb8009ecac5e2' 0.0 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bnzJje_-rTXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train[train.id == '000bec180eb18c7604dcecc8fe0dba07'].T.head(25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z2QPlW7Vp-qD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(train.groupby('id').idxmax(axis=1).reset_index())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "onXjFnVLsBi5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.iloc[:,2].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rtsjing4XAsV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DogsDataset(Dataset):\n",
        "    def __init__(self, labels, root_dir, subset=False, transform=None):\n",
        "        self.labels = labels\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = '{}.jpg'.format(self.labels.iloc[idx, 0])\n",
        "        fullname = join(self.root_dir, img_name)\n",
        "        image = Image.open(fullname)\n",
        "        labels = self.labels.iloc[idx, 1:].as_matrix().astype('float')\n",
        "        labels = np.argmax(labels)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return [image, labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgMtnwnmYqeV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_IMG_PATH = \"/content/train\"\n",
        "#TEST_IMG_PATH = \"/content/test\"\n",
        "LABELS_CSV_PATH = \"/content/labels.csv\"\n",
        "SAMPLE_SUB_PATH = \"/content/sample_submission.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FHpmSseeW3PY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CWHHDDT7XXtn",
        "colab_type": "code",
        "outputId": "d5793ecb-961a-4cdd-894f-c42aca215ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "ds_trans = transforms.Compose([transforms.Scale(224),\n",
        "                               transforms.CenterCrop(224),\n",
        "                               transforms.ToTensor(),\n",
        "                               normalize])\n",
        "train_ds = DogsDataset(train, TRAIN_IMG_PATH, transform=ds_trans)\n",
        "valid_ds = DogsDataset(valid, TRAIN_IMG_PATH, transform=ds_trans)\n",
        "\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=4)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=8, shuffle=True, num_workers=4)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "RBKbzVFZCOTO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataloaders = {\"train\": train_dl, \"valid\": valid_dl}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VL7XKlqRXdgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a9f7408a-5ca2-4c53-f765-e37f43c623bd"
      },
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet34(pretrained=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.torch/models/resnet34-333f7ec4.pth\n",
            "100%|██████████| 87306240/87306240 [00:00<00:00, 89366942.62it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hoNwfxsVD2qP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQ2vjKx4aE7H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "model.fc = nn.Linear(model.fc.in_features, 120)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fYxcNeJJebsR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cXAg4JLSr_iO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pu7gQpBUuW_Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import copy\n",
        "import sys\n",
        "dataset_sizes = {\"train\": len(train_ds),\"valid\":len(valid_ds)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f-rz5npJs5ZF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, dataloaders, device, num_epochs=25):\n",
        "    since = time()\n",
        "    model = model.to(device)\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    # Count training and validation examples\n",
        "    train_examples = len(dataloaders['train'].dataset)\n",
        "    valid_examples = len(dataloaders['valid'].dataset)\n",
        "\n",
        "    train_bs = dataloaders['train'].batch_size\n",
        "    valid_bs = dataloaders['valid'].batch_size\n",
        "    \n",
        "    # Calculate number of minibatches for training and validation\n",
        "    num_minibatch = {'train': int(np.ceil(train_examples / train_bs)), \n",
        "                     'valid': int(np.ceil(valid_examples / valid_bs))}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            mini_batch = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                mini_batch += 1\n",
        "                # Print status bar\n",
        "                if phase == 'train':\n",
        "                    mini_batch_comp = int((mini_batch/num_minibatch[phase])*100)//2\n",
        "                    sys.stdout.write('\\r')\n",
        "                    sys.stdout.write(\"%s[%-50s] %d%%\" %(phase, \"=\"*mini_batch_comp, 2*mini_batch_comp))\n",
        "                else:\n",
        "                    mini_batch_comp = int((mini_batch/num_minibatch[phase])*100)//5\n",
        "                    sys.stdout.write('\\r')\n",
        "                    sys.stdout.write(\"%s[%-20s] %d%%\" %(phase, \"=\"*mini_batch_comp, 5*mini_batch_comp))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(\"\")\n",
        "            print(f'{phase} Loss: {epoch_loss} Acc: {epoch_acc}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
        "    print(f'Best val Acc: {best_acc}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fskueM8ZtBpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "2d930dd1-7bcb-45cc-9986-932be471e8d7"
      },
      "cell_type": "code",
      "source": [
        "model = train_model(model, criterion, optimizer, dataloaders, device, num_epochs=3)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 1.2827251515052638 Acc: 0.6872095866960137\n",
            "valid[====================] 100%\n",
            "valid Loss: 1.3473306597810086 Acc: 0.7206457925636007\n",
            "\n",
            "Epoch 2/3\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 1.2555606317610517 Acc: 0.7092198581560284\n",
            "valid[====================] 100%\n",
            "valid Loss: 1.4037232650061175 Acc: 0.7402152641878669\n",
            "\n",
            "Epoch 3/3\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 1.2090853269360677 Acc: 0.723159696747371\n",
            "valid[====================] 100%\n",
            "valid Loss: 1.4286484673050635 Acc: 0.7446183953033267\n",
            "\n",
            "Training complete in 6.0m 0.7746415138244629s\n",
            "Best val Acc: 0.7446183953033267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IgVTgsfre3LP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model, \"dogscats_resnet34\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I8LdRbiEwrsd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = torch.load(\"dogscats_resnet34\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nW5r3pUiww0i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5wklkId3eoAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 120)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized / we have updated all the layer in the resnet architecture by passing model_ft.parameters()\n",
        "#to the optimizer , again SGD with momentum is preferred over Adam ?? \n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PtEMPbMfj0R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_find = lr_finder(model_ft, criterion, optimizer_ft, dataloaders, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uA8Vfjlo8Ap3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "174d7a30-9af9-4d57-edbf-7b6215231728"
      },
      "cell_type": "code",
      "source": [
        "lr_find.fit()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[============================                      ] 56%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bZW_VmgW8EsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "4d530836-fcc8-4d82-900b-d51242e79ebd"
      },
      "cell_type": "code",
      "source": [
        "lr_find.plot_lr()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFOCAYAAACxAKU1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e90cf0748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CuD63W5uglet",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_sizes = {\"train\": len(train_ds),\"val\":len(valid_ds)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVZso10k8DgT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Y_SwdVRhN35",
        "colab_type": "code",
        "outputId": "170e0058-5afc-41bc-e6b7-4d287336110e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(dataset_sizes)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': 8178, 'val': 2044}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hPSjAZLe9oZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3026
        },
        "outputId": "b5995654-ed46-4124-8cd0-8be191fe80b5"
      },
      "cell_type": "code",
      "source": [
        "model, lr_hist = train_model(model_ft, criterion, optimizer_ft, dataloaders, device, scheduler, num_epochs=25)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 1.063960767602769 Acc: 0.6724137931034483\n",
            "val[====================] 100%\n",
            "val Loss: 2.808013797972767 Acc: 0.3845401174168297\n",
            "\n",
            "Epoch 2/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.7867576776550229 Acc: 0.7578870139398386\n",
            "val[====================] 100%\n",
            "val Loss: 2.7865011904337633 Acc: 0.39774951076320936\n",
            "\n",
            "Epoch 3/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.5919074528839454 Acc: 0.8165810711665444\n",
            "val[====================] 100%\n",
            "val Loss: 3.4135780390461363 Acc: 0.36350293542074363\n",
            "\n",
            "Epoch 4/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.4393373880855143 Acc: 0.8630471998043532\n",
            "val[====================] 100%\n",
            "val Loss: 3.0258722988826654 Acc: 0.4207436399217221\n",
            "\n",
            "Epoch 5/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.34375611850643367 Acc: 0.8920273905600392\n",
            "val[====================] 100%\n",
            "val Loss: 3.0194288688163233 Acc: 0.39970645792563597\n",
            "\n",
            "Epoch 6/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.22885878988687203 Acc: 0.9295671313279531\n",
            "val[====================] 100%\n",
            "val Loss: 2.9382161095650927 Acc: 0.4432485322896281\n",
            "\n",
            "Epoch 7/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.1691429286459076 Acc: 0.9496209342137443\n",
            "val[====================] 100%\n",
            "val Loss: 3.0343167392241743 Acc: 0.45058708414872795\n",
            "\n",
            "Epoch 8/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.13326997300994867 Acc: 0.9608706285155295\n",
            "val[====================] 100%\n",
            "val Loss: 2.8386807635339038 Acc: 0.45939334637964774\n",
            "\n",
            "Epoch 9/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.06941576276906518 Acc: 0.9805575935436538\n",
            "val[====================] 100%\n",
            "val Loss: 2.8068640759313177 Acc: 0.4740704500978473\n",
            "\n",
            "Epoch 10/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.0531042569072534 Acc: 0.9858156028368795\n",
            "val[====================] 100%\n",
            "val Loss: 2.7540337068927263 Acc: 0.5073385518590998\n",
            "\n",
            "Epoch 11/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.05517823942776384 Acc: 0.9855710442651016\n",
            "val[====================] 100%\n",
            "val Loss: 2.7857058601136777 Acc: 0.48336594911937375\n",
            "\n",
            "Epoch 12/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.054594978839559875 Acc: 0.9852042064074347\n",
            "val[====================] 100%\n",
            "val Loss: 2.665110680455098 Acc: 0.485812133072407\n",
            "\n",
            "Epoch 13/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.026796999640032144 Acc: 0.9938860357055516\n",
            "val[====================] 100%\n",
            "val Loss: 2.502229400810197 Acc: 0.5264187866927592\n",
            "\n",
            "Epoch 14/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.032651415195404446 Acc: 0.9905844949865493\n",
            "val[====================] 100%\n",
            "val Loss: 2.6876861384236883 Acc: 0.49363992172211346\n",
            "\n",
            "Epoch 15/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.03532405994608397 Acc: 0.9902176571288824\n",
            "val[====================] 100%\n",
            "val Loss: 2.633531391503993 Acc: 0.49902152641878667\n",
            "\n",
            "Epoch 16/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.024434926137273483 Acc: 0.9933969185619956\n",
            "val[====================] 100%\n",
            "val Loss: 2.679817155615924 Acc: 0.5146771037181996\n",
            "\n",
            "Epoch 17/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.021423058802529343 Acc: 0.9951088285644413\n",
            "val[====================] 100%\n",
            "val Loss: 2.717041641532092 Acc: 0.5034246575342466\n",
            "\n",
            "Epoch 18/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.010368305769780645 Acc: 0.9981658107116655\n",
            "val[====================] 100%\n",
            "val Loss: 2.6474896389444282 Acc: 0.5229941291585127\n",
            "\n",
            "Epoch 19/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.012849232246135843 Acc: 0.9966984592809979\n",
            "val[====================] 100%\n",
            "val Loss: 2.6251496624806623 Acc: 0.5161448140900196\n",
            "\n",
            "Epoch 20/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.008565600328265848 Acc: 0.9982880899975545\n",
            "val[====================] 100%\n",
            "val Loss: 2.59150722978633 Acc: 0.5200587084148728\n",
            "\n",
            "Epoch 21/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.004557099660704089 Acc: 0.9991440449987773\n",
            "val[====================] 100%\n",
            "val Loss: 2.6819474470825346 Acc: 0.5122309197651663\n",
            "\n",
            "Epoch 22/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.010349113511467773 Acc: 0.9979212521398876\n",
            "val[====================] 100%\n",
            "val Loss: 2.737662490100077 Acc: 0.5029354207436398\n",
            "\n",
            "Epoch 23/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.006568843620451426 Acc: 0.9986549278552214\n",
            "val[====================] 100%\n",
            "val Loss: 2.664798330887423 Acc: 0.5151663405088063\n",
            "\n",
            "Epoch 24/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.006238522113287877 Acc: 0.9987772071411104\n",
            "val[====================] 100%\n",
            "val Loss: 2.661937414783321 Acc: 0.5181017612524461\n",
            "\n",
            "Epoch 25/25\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 0.008093630547452364 Acc: 0.9981658107116655\n",
            "val[====================] 100%\n",
            "val Loss: 2.6320952130390474 Acc: 0.5161448140900196\n",
            "\n",
            "Training complete in 56.0m 2.4834671020507812s\n",
            "Best val Acc: 0.5264187866927592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZbAJdYosfDI-",
        "colab_type": "code",
        "outputId": "49c8eee5-9616-4d14-866f-3ea848d70a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,device,\n",
        "                       num_epochs=5)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-327733e582a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=5)\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train_model() missing 2 required positional arguments: 'device' and 'scheduler'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9iihBtkApeRt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f7858f83-fdb0-4146-d23d-1883f4ffcb24"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels.csv\tsample_data\t       sample_submission.csv.zip  train\n",
            "labels.csv.zip\tsample_submission.csv  test.zip\t\t\t  train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uKRb6JlO5xlF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Identifying the layer name in the ResNet is difficult bcoz same name is given for the conv / relu / for each layer , so it is better to find the freeze layer manually and use it as below \n",
        "'''def get_count(layer_name,model_name):\n",
        "  ct  = 0 \n",
        "  layer_count ={}\n",
        "  for name, child in model_name.named_children():\n",
        "      for name2, params in child.named_parameters():\n",
        "        layer_count[name2] = ct\n",
        "        ct +=1\n",
        "  return layer_count[layer_name]\n",
        "\n",
        "def freeze_till(layer_name,model_name):\n",
        "  ct  = 0 \n",
        "  count = get_count(layer_name,model_name)\n",
        "  \n",
        "  for name, child in model_name.named_children():\n",
        "    for name2, params in child.named_parameters():\n",
        "      \n",
        "      if ct > count :\n",
        "          \n",
        "            params.requires_grad = True\n",
        "      else :\n",
        "            params.requires_grad = False\n",
        "      ct +=1 '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q1zHFKpgMBht",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_conv = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "ct = 0\n",
        "for name, child in model_conv.named_children():\n",
        "    ct += 1\n",
        "    if ct < 8:\n",
        "        for name2, params in child.named_parameters():\n",
        "          params.requires_grad = False       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jedAaPQQPcGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2924
        },
        "outputId": "95a3bd13-29cb-4120-f565-ba8fb22687c7"
      },
      "cell_type": "code",
      "source": [
        "# To view which layers are freeze and which layers are not freezed:\n",
        "\n",
        "for name, child in model_conv.named_children():\n",
        "  print ('name :',name)\n",
        "  for name_2, params in child.named_parameters():\n",
        "    print(name_2, params.requires_grad)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name : conv1\n",
            "weight False\n",
            "name : bn1\n",
            "weight False\n",
            "bias False\n",
            "name : relu\n",
            "name : maxpool\n",
            "name : layer1\n",
            "0.conv1.weight False\n",
            "0.bn1.weight False\n",
            "0.bn1.bias False\n",
            "0.conv2.weight False\n",
            "0.bn2.weight False\n",
            "0.bn2.bias False\n",
            "0.conv3.weight False\n",
            "0.bn3.weight False\n",
            "0.bn3.bias False\n",
            "0.downsample.0.weight False\n",
            "0.downsample.1.weight False\n",
            "0.downsample.1.bias False\n",
            "1.conv1.weight False\n",
            "1.bn1.weight False\n",
            "1.bn1.bias False\n",
            "1.conv2.weight False\n",
            "1.bn2.weight False\n",
            "1.bn2.bias False\n",
            "1.conv3.weight False\n",
            "1.bn3.weight False\n",
            "1.bn3.bias False\n",
            "2.conv1.weight False\n",
            "2.bn1.weight False\n",
            "2.bn1.bias False\n",
            "2.conv2.weight False\n",
            "2.bn2.weight False\n",
            "2.bn2.bias False\n",
            "2.conv3.weight False\n",
            "2.bn3.weight False\n",
            "2.bn3.bias False\n",
            "name : layer2\n",
            "0.conv1.weight False\n",
            "0.bn1.weight False\n",
            "0.bn1.bias False\n",
            "0.conv2.weight False\n",
            "0.bn2.weight False\n",
            "0.bn2.bias False\n",
            "0.conv3.weight False\n",
            "0.bn3.weight False\n",
            "0.bn3.bias False\n",
            "0.downsample.0.weight False\n",
            "0.downsample.1.weight False\n",
            "0.downsample.1.bias False\n",
            "1.conv1.weight False\n",
            "1.bn1.weight False\n",
            "1.bn1.bias False\n",
            "1.conv2.weight False\n",
            "1.bn2.weight False\n",
            "1.bn2.bias False\n",
            "1.conv3.weight False\n",
            "1.bn3.weight False\n",
            "1.bn3.bias False\n",
            "2.conv1.weight False\n",
            "2.bn1.weight False\n",
            "2.bn1.bias False\n",
            "2.conv2.weight False\n",
            "2.bn2.weight False\n",
            "2.bn2.bias False\n",
            "2.conv3.weight False\n",
            "2.bn3.weight False\n",
            "2.bn3.bias False\n",
            "3.conv1.weight False\n",
            "3.bn1.weight False\n",
            "3.bn1.bias False\n",
            "3.conv2.weight False\n",
            "3.bn2.weight False\n",
            "3.bn2.bias False\n",
            "3.conv3.weight False\n",
            "3.bn3.weight False\n",
            "3.bn3.bias False\n",
            "name : layer3\n",
            "0.conv1.weight False\n",
            "0.bn1.weight False\n",
            "0.bn1.bias False\n",
            "0.conv2.weight False\n",
            "0.bn2.weight False\n",
            "0.bn2.bias False\n",
            "0.conv3.weight False\n",
            "0.bn3.weight False\n",
            "0.bn3.bias False\n",
            "0.downsample.0.weight False\n",
            "0.downsample.1.weight False\n",
            "0.downsample.1.bias False\n",
            "1.conv1.weight False\n",
            "1.bn1.weight False\n",
            "1.bn1.bias False\n",
            "1.conv2.weight False\n",
            "1.bn2.weight False\n",
            "1.bn2.bias False\n",
            "1.conv3.weight False\n",
            "1.bn3.weight False\n",
            "1.bn3.bias False\n",
            "2.conv1.weight False\n",
            "2.bn1.weight False\n",
            "2.bn1.bias False\n",
            "2.conv2.weight False\n",
            "2.bn2.weight False\n",
            "2.bn2.bias False\n",
            "2.conv3.weight False\n",
            "2.bn3.weight False\n",
            "2.bn3.bias False\n",
            "3.conv1.weight False\n",
            "3.bn1.weight False\n",
            "3.bn1.bias False\n",
            "3.conv2.weight False\n",
            "3.bn2.weight False\n",
            "3.bn2.bias False\n",
            "3.conv3.weight False\n",
            "3.bn3.weight False\n",
            "3.bn3.bias False\n",
            "4.conv1.weight False\n",
            "4.bn1.weight False\n",
            "4.bn1.bias False\n",
            "4.conv2.weight False\n",
            "4.bn2.weight False\n",
            "4.bn2.bias False\n",
            "4.conv3.weight False\n",
            "4.bn3.weight False\n",
            "4.bn3.bias False\n",
            "5.conv1.weight False\n",
            "5.bn1.weight False\n",
            "5.bn1.bias False\n",
            "5.conv2.weight False\n",
            "5.bn2.weight False\n",
            "5.bn2.bias False\n",
            "5.conv3.weight False\n",
            "5.bn3.weight False\n",
            "5.bn3.bias False\n",
            "name : layer4\n",
            "0.conv1.weight True\n",
            "0.bn1.weight True\n",
            "0.bn1.bias True\n",
            "0.conv2.weight True\n",
            "0.bn2.weight True\n",
            "0.bn2.bias True\n",
            "0.conv3.weight True\n",
            "0.bn3.weight True\n",
            "0.bn3.bias True\n",
            "0.downsample.0.weight True\n",
            "0.downsample.1.weight True\n",
            "0.downsample.1.bias True\n",
            "1.conv1.weight True\n",
            "1.bn1.weight True\n",
            "1.bn1.bias True\n",
            "1.conv2.weight True\n",
            "1.bn2.weight True\n",
            "1.bn2.bias True\n",
            "1.conv3.weight True\n",
            "1.bn3.weight True\n",
            "1.bn3.bias True\n",
            "2.conv1.weight True\n",
            "2.bn1.weight True\n",
            "2.bn1.bias True\n",
            "2.conv2.weight True\n",
            "2.bn2.weight True\n",
            "2.bn2.bias True\n",
            "2.conv3.weight True\n",
            "2.bn3.weight True\n",
            "2.bn3.bias True\n",
            "name : avgpool\n",
            "name : fc\n",
            "weight True\n",
            "bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JZQ1nLYHEDDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28b0cb93-7932-4f73-9174-add241408a6c"
      },
      "cell_type": "code",
      "source": [
        "len(list(filter(lambda p: p.requires_grad, model_conv.parameters())))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "BOVwB05isbSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JtJEnbjjibPH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 120)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#model_conv = freeze_till('transition2.conv.weight',model_conv)\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opoosed to before.\n",
        "optimizer_conv = optim.SGD(list(filter(lambda p: p.requires_grad, model_conv.parameters())), lr=0.001, momentum=0.9)\n",
        ".\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k3EQ72LcjglF",
        "colab_type": "code",
        "outputId": "a6437a40-3079-4199-b307-be52240b1e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=5)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 2.3948 Acc: 0.4585\n",
            "val Loss: 0.7969 Acc: 0.7588\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.9838 Acc: 0.7402\n",
            "val Loss: 0.6855 Acc: 0.7779\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 0.6495 Acc: 0.8276\n",
            "val Loss: 0.6459 Acc: 0.7935\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 0.4361 Acc: 0.8842\n",
            "val Loss: 0.6362 Acc: 0.8082\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.2886 Acc: 0.9274\n",
            "val Loss: 0.6789 Acc: 0.7975\n",
            "\n",
            "Training complete in 11m 55s\n",
            "Best val Acc: 0.808219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UxujhiGJsMYc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class lr_finder():\n",
        "    \n",
        "    \"\"\"Implementation of LR Find function explained in the paper:\n",
        "        https://arxiv.org/abs/1506.01186\n",
        "        Tries a range of Learning Rates and returns the loss for\n",
        "        the entire range.\n",
        "        \n",
        "        Args:\n",
        "            model: Network for which the LR has to be found\n",
        "            criterion: Loss function\n",
        "            optimizer: pytorch optimizer\n",
        "                Optimizer can have different param_groups for\n",
        "                    different layers of the network to have \n",
        "                    different LRs. The layers should be in order\n",
        "                    of closeness to the input. i.e. the layer \n",
        "                    closest to the input should be the first and\n",
        "                    the last layer before the loss function should\n",
        "                    be the last\n",
        "            dataloaders: Dictionary containing DataLoader for \"train\"\n",
        "            device: \"CPU\" or \"CUDA\"\n",
        "            factor: Factor by which the LR has to be reduced for the\n",
        "                earlier groups. For e.g. if the factor is 10, then if \n",
        "                the last group has a LR of 0.2, the group ahead of it \n",
        "                will have a LR of 0.02 and the one ahead of the second\n",
        "                group will have an LR of 0.002 and so on.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model, criterion, optimizer, dataloaders, device, factor=10):\n",
        "        \n",
        "        model = model.to(device)\n",
        "        self.model = model.train()\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.dataloaders = dataloaders\n",
        "        self.device = device\n",
        "        self.results = None\n",
        "        self.factor = factor\n",
        "        \n",
        "    def fit(self):\n",
        "        \n",
        "        # Count number of examples in train dataset\n",
        "        train_examples = len(self.dataloaders['train'].dataset)\n",
        "        train_bs = self.dataloaders['train'].batch_size\n",
        "        # Count number of mini batches\n",
        "        mini_batches = train_examples // train_bs\n",
        "        increment = 16 / mini_batches\n",
        "        \n",
        "        # Start with a very low LR for the last layer\n",
        "        lr_hist = []\n",
        "        # Save loss history of the last layer\n",
        "        loss_hist = []\n",
        "        cur_lr = 1e-3\n",
        "        \n",
        "        mini_batch = 0\n",
        "        for inputs, labels in self.dataloaders['train']:\n",
        "            \n",
        "            # Print status bar\n",
        "            mini_batch_comp = int((mini_batch/mini_batches)*100)//2\n",
        "            sys.stdout.write('\\r')\n",
        "            sys.stdout.write(\"[%-50s] %d%%\" %(\"=\"*mini_batch_comp, 2*mini_batch_comp))\n",
        "            mini_batch += 1\n",
        "            \n",
        "            model = self.model\n",
        "            criterion = self.criterion\n",
        "            optimizer = self.optimizer\n",
        "            device = self.device\n",
        "            \n",
        "            # Set differential learning rates for various param groups based \n",
        "            # on factor value\n",
        "            fa = 0\n",
        "            for pg in optimizer.param_groups[::-1]:\n",
        "                pg['lr'] = cur_lr / (self.factor ** fa)\n",
        "                fa += 1\n",
        "            lr_ = []\n",
        "            for pg in optimizer.param_groups:\n",
        "                lr_.append(pg['lr'])\n",
        "            lr_hist.append(lr_)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            loss_hist.append(loss.item())\n",
        "            cur_lr = cur_lr + (lr_hist[-1][-1] * increment)\n",
        "            \n",
        "            if cur_lr == 0:\n",
        "                cur_lr += increment\n",
        "            \n",
        "            # Stop iteration at a LR of 1e1\n",
        "            if cur_lr > 10:\n",
        "                break\n",
        "                \n",
        "            # Stop iteration is loss is getting too high\n",
        "            if (loss > (5*loss_hist[0])) & (cur_lr > .1):\n",
        "                break\n",
        "            \n",
        "            if (lr_hist[-1][-1] * 10 - cur_lr) < (increment * lr_hist[-1][-1]):\n",
        "                # Reset when LR is reduced by a factor of 10 \n",
        "                cur_lr = round(lr_hist[-1][-1]*10, 8)\n",
        "        \n",
        "        if len(lr_hist) > len(loss_hist):\n",
        "            lr_hist.pop(-1)\n",
        "                \n",
        "        self.results = {'lr': lr_hist, 'loss': loss_hist}\n",
        "        self.results['loss'] = self.moving_average()\n",
        "                     \n",
        "    def plot_lr(self):\n",
        "        \n",
        "        # Plot LR vs Loss\n",
        "        if self.results:\n",
        "            lr_ = [i[-1] for i in self.results[\"lr\"]]\n",
        "            plt.plot(lr_, self.results['loss'])\n",
        "            plt.xscale(\"log\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"Results not available\")\n",
        "            \n",
        "    def moving_average(self):\n",
        "        # Smoothen the loss by calculating moving average\n",
        "        loss_hist = np.cumsum(self.results['loss'])\n",
        "        loss_hist /= np.arange(1, len(loss_hist)+1)\n",
        "        return loss_hist\n",
        "    \n",
        "    def lr_schedule(self, group = -1):\n",
        "        # Plot LR schedule\n",
        "        lr_ = [i[group] for i in self.results[\"lr\"]]\n",
        "        plt.plot(lr_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xmS18tjxFSfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_find = lr_finder(model_conv, criterion, optimizer_conv, dataloaders, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tf2BPOJOtba3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c02f1544-d039-44ff-e471-5e93bd4c0cc9"
      },
      "cell_type": "code",
      "source": [
        "lr_find.fit()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==============                                    ] 28%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xgbyAvOjt4Tb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "294b327e-f7fd-4ebb-f44e-8f4627c5ae83"
      },
      "cell_type": "code",
      "source": [
        "lr_find.lr_schedule()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmFG+AACEGeULAECYUb4AAITZ/wfHd/hPOhCwDQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e91481ef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "A-zXee7atjt3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "c351cb3c-0cbc-4344-b1af-d636200ca7b2"
      },
      "cell_type": "code",
      "source": [
        "lr_find.plot_lr()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFOCAYAAACxAKU1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e9178bf28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wRnirI6yuVBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
        "        transforms.RandomRotation(degrees=10, resample=False, expand=False, center=None),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AMxd1xSHwciD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class _LRScheduler_(object):\n",
        "    # Modified code from torch.optim.lr_scheduler\n",
        "    def __init__(self, optimizer, last_batch=-1):\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "        if last_batch == -1:\n",
        "            for group in optimizer.param_groups:\n",
        "                group.setdefault('initial_lr', group['lr'])\n",
        "        else:\n",
        "            for i, group in enumerate(optimizer.param_groups):\n",
        "                if 'initial_lr' not in group:\n",
        "                    raise KeyError(\"param 'initial_lr' is not specified \"\n",
        "                                   \"in param_groups[{}] when resuming an optimizer\".format(i))\n",
        "        self.base_lrs = list(map(lambda group: group['initial_lr'], optimizer.param_groups))\n",
        "        self.step(last_batch + 1)\n",
        "        self.last_batch = last_batch\n",
        "\n",
        "    def state_dict(self):\n",
        "        \"\"\"Returns the state of the scheduler as a :class:`dict`.\n",
        "\n",
        "        It contains an entry for every variable in self.__dict__ which\n",
        "        is not the optimizer.\n",
        "        \"\"\"\n",
        "        return {key: value for key, value in self.__dict__.items() if key != 'optimizer'}\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        \"\"\"Loads the schedulers state.\n",
        "\n",
        "        Arguments:\n",
        "            state_dict (dict): scheduler state. Should be an object returned\n",
        "                from a call to :meth:`state_dict`.\n",
        "        \"\"\"\n",
        "        self.__dict__.update(state_dict)\n",
        "\n",
        "    def get_lr(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def step(self, batch=None):\n",
        "        if batch is None:\n",
        "            batch = self.last_batch + 1\n",
        "        self.last_batch = batch\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cg-BopQ7wjPI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CosineAnnealingLR_(_LRScheduler_):\n",
        "    # Modified code from torch.optim.lr_scheduler\n",
        "    r\"\"\"Set the learning rate of each parameter group using a cosine annealing\n",
        "    schedule, where :math:`\\eta_{max}` is set to the initial lr and\n",
        "    :math:`T_{cur}` is the number of epochs since the last restart in SGDR:\n",
        "\n",
        "    .. math::\n",
        "\n",
        "        \\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 +\n",
        "        \\cos(\\frac{T_{cur}}{T_{max}}\\pi))\n",
        "\n",
        "    When last_epoch=-1, sets initial lr as lr.\n",
        "\n",
        "    It has been proposed in\n",
        "    `SGDR: Stochastic Gradient Descent with Warm Restarts`_. Note that this only\n",
        "    implements the cosine annealing part of SGDR, and not the restarts.\n",
        "\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        T_max (int): Maximum number of iterations.\n",
        "        eta_min (float): Minimum learning rate. Default: 0.\n",
        "        last_epoch (int): The index of last epoch. Default: -1.\n",
        "\n",
        "    .. _SGDR\\: Stochastic Gradient Descent with Warm Restarts:\n",
        "        https://arxiv.org/abs/1608.03983\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, T_max, eta_min=0, last_batch=-1):\n",
        "        self.T_max = T_max\n",
        "        self.eta_min = eta_min\n",
        "        super(CosineAnnealingLR_, self).__init__(optimizer, last_batch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [self.eta_min + (base_lr - self.eta_min) *\n",
        "                (1 + math.cos(math.pi * self.last_batch / self.T_max)) / 2\n",
        "                for base_lr in self.base_lrs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wt-xQ4BXworZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SGDR(CosineAnnealingLR_):\n",
        "    r\"\"\"Implements cosine annealing of LR\n",
        "    Args:\n",
        "        iterations: no. of iterations after which LR has to be reset\n",
        "            in general iterations must be equal to no. of minibatches in \n",
        "            a training epoch\n",
        "        cycle_mult: factor by which the iteration cycle has to be \n",
        "            increased after every cycle. Default: 1\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, T_max, eta_min = 0, last_batch = -1, cycle_mult = 1):\n",
        "        self.cycle_mult = cycle_mult\n",
        "        super(SGDR, self).__init__(optimizer, T_max, eta_min, last_batch)\n",
        "        \n",
        "    def step(self, batch=None):\n",
        "        if batch is None:\n",
        "            batch = self.last_batch + 1\n",
        "        self.last_batch = batch\n",
        "        if ((self.last_batch%self.T_max) == 0) & (self.last_batch != 0):\n",
        "            # Reset after T_max number of iterations are reached\n",
        "            self.last_batch = 0\n",
        "            self.T_max = self.T_max * self.cycle_mult\n",
        "            # Increase T_max by cycle_mult after each cycle\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4GsiX7BjzKAE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import PIL\n",
        "import math\n",
        "import copy\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from functools import partial\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from bisect import bisect_right\n",
        "from torch.optim import Optimizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets, models, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sXz74xDswvf6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "scheduler = SGDR(optimizer = optimizer_conv, T_max = 360)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRMFkPnfxE5t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, dataloaders, device, scheduler, num_epochs=25):\n",
        "    lr_hist = []\n",
        "    since = time()\n",
        "    model = model.to(device)\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    # Count training and validation examples\n",
        "    train_examples = len(dataloaders['train'].dataset)\n",
        "    valid_examples = len(dataloaders['val'].dataset)\n",
        "\n",
        "    train_bs = dataloaders['train'].batch_size\n",
        "    valid_bs = dataloaders['val'].batch_size\n",
        "    \n",
        "    # Calculate number of minibatches for training and validation\n",
        "    num_minibatch = {'train': int(np.ceil(train_examples / train_bs)), \n",
        "                     'val': int(np.ceil(valid_examples / valid_bs))}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            mini_batch = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                mini_batch += 1\n",
        "                # Print status bar\n",
        "                if phase == 'train':\n",
        "                    mini_batch_comp = int((mini_batch/num_minibatch[phase])*100)//2\n",
        "                    sys.stdout.write('\\r')\n",
        "                    sys.stdout.write(\"%s[%-50s] %d%%\" %(phase, \"=\"*mini_batch_comp, 2*mini_batch_comp))\n",
        "                else:\n",
        "                    mini_batch_comp = int((mini_batch/num_minibatch[phase])*100)//5\n",
        "                    sys.stdout.write('\\r')\n",
        "                    sys.stdout.write(\"%s[%-20s] %d%%\" %(phase, \"=\"*mini_batch_comp, 5*mini_batch_comp))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        scheduler.step()\n",
        "                        lr_ = []\n",
        "                        for group in optimizer.param_groups:\n",
        "                            lr_.append(group[\"lr\"])\n",
        "                        lr_hist.append(lr_)\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(\"\")\n",
        "            print(f'{phase} Loss: {epoch_loss} Acc: {epoch_acc}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
        "    print(f'Best val Acc: {best_acc}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, lr_hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W74XetL63Q6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet34(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, 120)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2i0tGTSv4x_t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5UEfcQNzf9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1982
        },
        "outputId": "58190219-b037-49a1-cb44-7cc2c229959b"
      },
      "cell_type": "code",
      "source": [
        "model, lr_hist = train_model(model, criterion, optimizer_conv, dataloaders, device, scheduler, num_epochs=3)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "----------\n",
            "train[==================================================] 100%\n",
            "train Loss: 5.048536408877542 Acc: 0.007825874296894107\n",
            "val[====================] 100%\n",
            "val Loss: 5.049256294907423 Acc: 0.008806262230919765\n",
            "\n",
            "Epoch 2/3\n",
            "----------\n",
            "train[============                                      ] 24%"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-165:\n",
            "Process Process-168:\n",
            "Process Process-167:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
            "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
            "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
            "Traceback (most recent call last):\n",
            "Process Process-166:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"<ipython-input-11-6b8623b41ca1>\", line 17, in __getitem__\n",
            "    image = self.transform(image)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
            "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
            "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
            "    img = t(img)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
            "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
            "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 138, in default_collate\n",
            "    return [default_collate(samples) for samples in transposed]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
            "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
            "  File \"<ipython-input-11-6b8623b41ca1>\", line 17, in __getitem__\n",
            "    image = self.transform(image)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
            "    return F.resize(img, self.size, self.interpolation)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-534eafa75eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-112-6e1663dbcc15>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataloaders, device, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                         \u001b[0mlr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
            "    return [default_collate(samples) for samples in transposed]\n",
            "  File \"<ipython-input-11-6b8623b41ca1>\", line 17, in __getitem__\n",
            "    image = self.transform(image)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
            "    img = t(img)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 204, in resize\n",
            "    return img.resize((ow, oh), interpolation)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 1782, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
            "    img = t(img)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
            "    return F.resize(img, self.size, self.interpolation)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
            "    return torch.stack(batch, 0, out=out)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\", line 239, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
            "    return F.resize(img, self.size, self.interpolation)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 200, in resize\n",
            "    return img.resize((ow, oh), interpolation)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 1782, in resize\n",
            "    self.load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\", line 239, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 200, in resize\n",
            "    return img.resize((ow, oh), interpolation)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 1782, in resize\n",
            "    self.load()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\", line 239, in load\n",
            "    n, err_code = decoder.decode(b)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5DgOA5xeznf1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_find = lr_finder(model, criterion, optimizer_conv, dataloaders, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvSw5AJx44-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0481fd8-16f6-491a-8aa8-042d8af0cb03"
      },
      "cell_type": "code",
      "source": [
        "lr_find.fit()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==============                                    ] 28%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ReIc-e5D47pM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "2c04c759-5e61-41ca-ec6a-91cd4080d9b3"
      },
      "cell_type": "code",
      "source": [
        "lr_find.plot_lr()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFOCAYAAACxAKU1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e95f856a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XQ43-BO15H7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}