{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_Embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/stanimman/Simple/blob/master/Titanic_Embedding.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WjJ2sy-r8pyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a4f66841-c21f-432a-ee45-7ac5756ab2c2"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install  -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oVss_z6z88u2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193
        },
        "outputId": "e5f5e44f-d980-479b-bbd6-48923edcd40d"
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!cd data\n",
        "!pip install kaggle-cli\n",
        "!kg download -u 'stanimman' -p '***' -c 'titanic'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle-cli\n",
            "  Downloading https://files.pythonhosted.org/packages/67/61/710d02460bc4367ffd1f5e71cd9c031fb278f78aa0e8e32ca9dd99a2add8/kaggle-cli-0.12.13.tar.gz\n",
            "Collecting cliff<2.9,>=2.8.0 (from kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/e8/140ad9b5826920a8b85c187095e7725b87b913fc40243aa66dd04e9d82d6/cliff-2.8.1.tar.gz (73kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 4.1MB/s \n",
            "\u001b[?25hCollecting MechanicalSoup<0.9,>=0.7.0 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2e/f63ed26b51e36efa4cc22cad18187fcb0a253f756d548c96bb931f13de98/MechanicalSoup-0.8.0-py2.py3-none-any.whl\n",
            "Collecting lxml<4.1,>=4.0.0 (from kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/b5/4c6995f8f259f0858f79460e6d277888f8498ce1c1a466dfbb24f06ba83f/lxml-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.3MB 6.7MB/s \n",
            "\u001b[?25hCollecting cssselect<1.1,>=1.0.1 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
            "Collecting configparser (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/69/c2ce7e91c89dc073eb1aa74c0621c3eefbffe8216b3f9af9d3885265c01c/configparser-3.5.0.tar.gz\n",
            "Collecting progressbar2<3.35,>=3.34.3 (from kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/31/b984e17bcc7491c1baeda3906fe3abc14cb5cd5dbd046ab46d9fc7a2edfd/progressbar2-3.34.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4<4.7,>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from kaggle-cli) (4.6.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/5d/c196041ffdf3e34ba206db6d61d1f893a75e1f3435699ade9bd65e089a3d/pbr-4.0.4-py2.py3-none-any.whl (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 22.6MB/s \n",
            "\u001b[?25hCollecting cmd2>=0.6.7 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/17/76a4dc6ac0e0281d87387fd2cbb9cc92ece379c590d9acb7a1693e4aebd8/cmd2-0.9.1-py3-none-any.whl (70kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 20.1MB/s \n",
            "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.1 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (2.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (1.11.0)\n",
            "Collecting stevedore>=1.20.0 (from cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/17/6b/3b7d6d08b2ab3e5ef09e01c9f7b3b590ee135f289bb94553419e40922c25/stevedore-1.28.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff<2.9,>=2.8.0->kaggle-cli) (3.12)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2.18.4)\n",
            "Collecting python-utils>=2.1.0 (from progressbar2<3.35,>=3.34.3->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/a0/19119d8b7c05be49baf6c593f11c432d571b70d805f2fe94c0585e55e4c8/python_utils-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli) (0.1.7)\n",
            "Collecting pyperclip>=1.5.27 (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/15/f3c29b381815ae75e27589583655f4a8567721c541b8ba8cd52f76868655/pyperclip-1.6.2.tar.gz\n",
            "Collecting colorama (from cmd2>=0.6.7->cliff<2.9,>=2.8.0->kaggle-cli)\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2018.4.16)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->MechanicalSoup<0.9,>=0.7.0->kaggle-cli) (1.22)\n",
            "Building wheels for collected packages: kaggle-cli, cliff, configparser, PrettyTable, pyperclip\n",
            "  Running setup.py bdist_wheel for kaggle-cli ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/d5/bb/10/c1dd1b08c7433c943cb55c46367ae3f891415e8a37300ff8a7\n",
            "  Running setup.py bdist_wheel for cliff ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/50/00/6d/d4aeb5ccdd47dd76800592b26f943e4959bc705b2d4e6e54e1\n",
            "  Running setup.py bdist_wheel for configparser ... \u001b[?25l-"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \bdone\r\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/a3/61/79/424ef897a2f3b14684a7de5d89e8600b460b89663e6ce9d17c\n",
            "  Running setup.py bdist_wheel for PrettyTable ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Running setup.py bdist_wheel for pyperclip ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/58/32/92/2227fba72f0702e4168f084c6dfc2d6d3fd1904634ab61ca6a\n",
            "Successfully built kaggle-cli cliff configparser PrettyTable pyperclip\n",
            "Installing collected packages: pbr, pyperclip, colorama, cmd2, PrettyTable, stevedore, cliff, MechanicalSoup, lxml, cssselect, configparser, python-utils, progressbar2, kaggle-cli\n",
            "Successfully installed MechanicalSoup-0.8.0 PrettyTable-0.7.2 cliff-2.8.1 cmd2-0.9.1 colorama-0.3.9 configparser-3.5.0 cssselect-1.0.3 kaggle-cli-0.12.13 lxml-4.0.0 pbr-4.0.4 progressbar2-3.34.3 pyperclip-1.6.2 python-utils-2.3.0 stevedore-1.28.0\n",
            "downloading https://www.kaggle.com/c/titanic/download/train.csv\n",
            "\n",
            "train.csv 100% |####################################| Time: 0:00:00 184.8 KiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/titanic/download/test.csv\n",
            "\n",
            "test.csv 100% |#####################################| Time: 0:00:00  74.8 KiB/s\n",
            "\n",
            "downloading https://www.kaggle.com/c/titanic/download/gender_submission.csv\n",
            "\n",
            "gender_submission.csv 100% |########################| Time: 0:00:00  10.1 KiB/s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aR5rIJJ39Rxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5ea49bc9-7f14-4c41-ee7c-1bd7ab0038e6"
      },
      "cell_type": "code",
      "source": [
        "! apt install unzip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n",
            "Archive:  application_train.csv.zip\n",
            "  inflating: application_train.csv   \n",
            "Archive:  application_test.csv.zip\n",
            "  inflating: application_test.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2_V3vNRW9qfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# numpy and pandas for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "# sklearn preprocessing for dealing with categorical variables\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# File system manangement\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IBQdp2hq-uD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cdef7c6f-f611-4f45-b27b-4496916e51bb"
      },
      "cell_type": "code",
      "source": [
        "!unzip application_train.csv.zip\n",
        "!unzip application_test.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  application_train.csv.zip\n",
            "  inflating: application_train.csv   \n",
            "Archive:  application_test.csv.zip\n",
            "  inflating: application_test.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3b7jjvKr-mnr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b048026-feb9-4908-b2b1-ec52c271be38"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  datalab  gender_submission.csv  test.csv\ttrain.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sq4EnHKc996W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "titanic_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "euZ_jPGmS7bF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
        "titanic_df = titanic_df.drop(['PassengerId','Name','Ticket'], axis=1)\n",
        "test_df    = test_df.drop(['Name','Ticket'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azy4ldcPTCHI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n",
        "titanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(\"S\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kty-g4aHTLOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fare\n",
        "\n",
        "# only for test_df, since there is a missing \"Fare\" values\n",
        "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n",
        "\n",
        "# convert from float to int\n",
        "titanic_df['Fare'] = titanic_df['Fare'].astype(int)\n",
        "test_df['Fare']    = test_df['Fare'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YmV2KY5Tpdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TpYZO-LpTinX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "e77a1268-4262-45b7-e2b5-74ee71e85ffd"
      },
      "cell_type": "code",
      "source": [
        "# Age \n",
        "\n",
        "fig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n",
        "axis1.set_title('Original Age values - Titanic')\n",
        "axis2.set_title('New Age values - Titanic')\n",
        "\n",
        "# axis3.set_title('Original Age values - Test')\n",
        "# axis4.set_title('New Age values - Test')\n",
        "\n",
        "# get average, std, and number of NaN values in titanic_df\n",
        "average_age_titanic   = titanic_df[\"Age\"].mean()\n",
        "std_age_titanic       = titanic_df[\"Age\"].std()\n",
        "count_nan_age_titanic = titanic_df[\"Age\"].isnull().sum()\n",
        "\n",
        "# get average, std, and number of NaN values in test_df\n",
        "average_age_test   = test_df[\"Age\"].mean()\n",
        "std_age_test       = test_df[\"Age\"].std()\n",
        "count_nan_age_test = test_df[\"Age\"].isnull().sum()\n",
        "\n",
        "# generate random numbers between (mean - std) & (mean + std)\n",
        "rand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\n",
        "rand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n",
        "\n",
        "# plot original Age values\n",
        "# NOTE: drop all null values, and convert to int\n",
        "titanic_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n",
        "# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n",
        "\n",
        "# fill NaN values in Age column with random values generated\n",
        "titanic_df[\"Age\"][np.isnan(titanic_df[\"Age\"])] = rand_1\n",
        "test_df[\"Age\"][np.isnan(test_df[\"Age\"])] = rand_2\n",
        "\n",
        "# convert from float to int\n",
        "titanic_df['Age'] = titanic_df['Age'].astype(int)\n",
        "test_df['Age']    = test_df['Age'].astype(int)\n",
        "        \n",
        "# plot new Age Values\n",
        "titanic_df['Age'].hist(bins=70, ax=axis2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f617c86beb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2UAAAEHCAYAAAAu1e4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f617cdf6eb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2g8nny9BT8gK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cabin\n",
        "# It has a lot of NaN values, so it won't cause a remarkable impact on prediction\n",
        "titanic_df.drop(\"Cabin\",axis=1,inplace=True)\n",
        "test_df.drop(\"Cabin\",axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SKNnz7QYUV2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4fcbc78d-e025-414e-92ca-5a781dde4fac"
      },
      "cell_type": "code",
      "source": [
        "# Family\n",
        "\n",
        "# Instead of having two columns Parch & SibSp, \n",
        "# we can have only one column represent if the passenger had any family member aboard or not,\n",
        "# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\n",
        "titanic_df['Family'] =  titanic_df[\"Parch\"] + titanic_df[\"SibSp\"]\n",
        "titanic_df['Family'].loc[titanic_df['Family'] > 0] = 1\n",
        "titanic_df['Family'].loc[titanic_df['Family'] == 0] = 0\n",
        "\n",
        "test_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\n",
        "test_df['Family'].loc[test_df['Family'] > 0] = 1\n",
        "test_df['Family'].loc[test_df['Family'] == 0] = 0\n",
        "\n",
        "# drop Parch & SibSp\n",
        "titanic_df = titanic_df.drop(['SibSp','Parch'], axis=1)\n",
        "test_df    = test_df.drop(['SibSp','Parch'], axis=1)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gf6anLtSUi69",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sex\n",
        "\n",
        "# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n",
        "# So, we can classify passengers as males, females, and child\n",
        "def get_person(passenger):\n",
        "    age,sex = passenger\n",
        "    return 'child' if age < 16 else sex\n",
        "    \n",
        "titanic_df['Person'] = titanic_df[['Age','Sex']].apply(get_person,axis=1)\n",
        "test_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n",
        "\n",
        "# No need to use Sex column since we created Person column\n",
        "titanic_df.drop(['Sex'],axis=1,inplace=True)\n",
        "test_df.drop(['Sex'],axis=1,inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-MsOztPCU4zL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define training and testing sets\n",
        "\n",
        "X_train = titanic_df.drop(\"Survived\",axis=1)\n",
        "Y_train = titanic_df[\"Survived\"]\n",
        "X_test  = test_df.drop(\"PassengerId\",axis=1).copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_xBrnk7aVia0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def missing_values_table(df):\n",
        "        # Total missing values\n",
        "        mis_val = df.isnull().sum()\n",
        "        \n",
        "        # Percentage of missing values\n",
        "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "        \n",
        "        # Make a table with the results\n",
        "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "        \n",
        "        # Rename the columns\n",
        "        mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "        \n",
        "        # Sort the table by percentage of missing descending\n",
        "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
        "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1)\n",
        "        \n",
        "        # Print some summary information\n",
        "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
        "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
        "              \" columns that have missing values.\")\n",
        "        \n",
        "        # Return the dataframe with missing information\n",
        "        return mis_val_table_ren_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GuhJPdGX-Zyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "88902a0e-208e-447f-da23-334e76ce1808"
      },
      "cell_type": "code",
      "source": [
        "missing_values_table(X_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your selected dataframe has 6 columns.\n",
            "There are 0 columns that have missing values.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Values</th>\n",
              "      <th>% of Total Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Missing Values, % of Total Values]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "dFoxFjyEVsO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cac7976f-7d30-4f9d-dc34-9c75dcf03747"
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "igYNOBPvWBdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0e047409-e578-4f58-eaea-4542923701de"
      },
      "cell_type": "code",
      "source": [
        "X_train.dtypes.value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int64     4\n",
              "object    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "YJ2W4BHWWAbF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1692e354-63a9-4c1c-f463-9bf5681b2cfe"
      },
      "cell_type": "code",
      "source": [
        "X_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embarked    3\n",
              "Person      3\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "3CXyt2e8WNoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ad266825-6a79-4759-bdeb-4967389eced8"
      },
      "cell_type": "code",
      "source": [
        "X_train.select_dtypes('int64').apply(pd.Series.nunique, axis = 0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pclass     3\n",
              "Age       71\n",
              "Fare      91\n",
              "Family     2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "aQ-Fs_ATWZsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "01d16ed2-fabc-4e32-c15c-29d1865a51bb"
      },
      "cell_type": "code",
      "source": [
        "print(Y_train.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(891,)\n",
            "(891, 6)\n",
            "(418, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5rmcW-RmXjJK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_nn = X_train\n",
        "Y_train_nn = Y_train\n",
        "X_test_nn = X_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W6wb2QedX19p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def label_encoding(app_train):\n",
        "  # Create a label encoder object\n",
        "  le = LabelEncoder()\n",
        "  le_count = 0\n",
        "\n",
        "  # Iterate through the columns\n",
        "  for col in app_train:\n",
        "      #if app_train[col].dtype == 'object':\n",
        "          # If 2 or fewer unique categories\n",
        "          if len(list(app_train[col].unique())):\n",
        "              # Train on the training data\n",
        "              le.fit(app_train[col])\n",
        "              # Transform both training and testing data\n",
        "              app_train[col] = le.transform(app_train[col])\n",
        "              \n",
        "              # Keep track of how many columns were label encoded\n",
        "              le_count += 1\n",
        "\n",
        "  print('%d columns were label encoded.' % le_count)\n",
        "  return app_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wsHYCjZuZBO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86d4d0ce-be8d-47ef-a617-2e8e3924a787"
      },
      "cell_type": "code",
      "source": [
        "X_train_nn_label = label_encoding(X_train_nn)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 columns were label encoded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yH9X1iAbZMig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "c4f53dd6-5667-42a4-ec54-c02d9da96a9f"
      },
      "cell_type": "code",
      "source": [
        "X_train_nn_label.head(2)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Family</th>\n",
              "      <th>Person</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass  Age  Fare  Embarked  Family  Person\n",
              "0       2   22     7         2       1       2\n",
              "1       0   38    71         0       1       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "metadata": {
        "id": "kLiAxBe_eOMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "2afa01b3-a544-4836-eba6-167ed282e7b7"
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5c428000 @  0x7fe7c2b561c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\r\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ea8GgHYaaJvh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_EY4Db9essi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cat_vars = ['Pclass','Embarked','Family','Person','Fare','Age']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-15uP2R4XeA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "samp_size = 891\n",
        "train_ratio = 0.75\n",
        "# train_ratio = 0.9\n",
        "train_size = int(samp_size * train_ratio); train_size\n",
        "val_idx = list(range(train_size, 891))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZIZzIbWaVh3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb_sz = []\n",
        "emb_sz = [len(list(X_train_nn_label[col].unique())) for col in X_train_nn_label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uuwl93meaEgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a95cbcb-7012-433d-c2d1-2bfbd86b9a61"
      },
      "cell_type": "code",
      "source": [
        "emb_sz"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 71, 91, 3, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "lC39PGlXccYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9n7okWw4XxUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb_szs = [(c, min(50, c)) for c in emb_sz]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pOTT0uzEdZR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f4d34cb-487a-4ffc-a136-9baa8d65899a"
      },
      "cell_type": "code",
      "source": [
        "emb_szs"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, 3), (71, 50), (91, 50), (3, 3), (2, 2), (3, 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "lsHbFXCAdzsw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z8Wz0xWAd7iZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize weight of Embedding matrix\n",
        "def emb_init(x):\n",
        "    x = x.weight.data\n",
        "    sc = 2/(x.size(1)+1)\n",
        "    x.uniform_(-sc,sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RcuV5_IxeHKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for emb in embs: emb_init(emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbR8yRp6eP7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "53288dbb-befc-4e3b-947b-9af64dace30a"
      },
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([0],dtype=torch.long) # you can obtain the weight from the embedding matrix only if you pass the tensor\n",
        "t2 = torch.tensor([2],dtype=torch.long)\n",
        "e1 = embs[0]\n",
        "e2 = embs[1]\n",
        "x1 = e1(t1)\n",
        "x2 = e1(t2)\n",
        "x = torch.cat([x1,x2],1)\n",
        "print(x1)\n",
        "print(x2)\n",
        "print(x)\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4206, -0.2134,  0.1855]])\n",
            "tensor([[ 0.1903, -0.0965,  0.2818]])\n",
            "tensor([[ 0.4206, -0.2134,  0.1855,  0.1903, -0.0965,  0.2818]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IrFNg5EyjFb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0748b68-4d38-4bf3-cba6-b40b41990852"
      },
      "cell_type": "code",
      "source": [
        "xyz = X_train_nn_label['Pclass']\n",
        "xyz.dtype"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "JnElT3RPjtYd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_numpy = X_train_nn_label.values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EP6uL2pOnJUa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_tensor = torch.from_numpy(df_numpy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QARU3rPIkhMM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_list = [e(df_tensor[:,i]) for i,e in enumerate(embs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WvV5Xgc0nuOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_new = torch.cat(x_list, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2l_roumn5Tr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa7b33d4-27a0-490e-ac50-9f087b1e98db"
      },
      "cell_type": "code",
      "source": [
        "x_new.shape"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([891, 111])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "metadata": {
        "id": "y7b3nsYIiXqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "7e1f6a6c-0eab-41be-838a-274d6241224a"
      },
      "cell_type": "code",
      "source": [
        "e1 = embs[3]\n",
        "e2 = embs[5]\n",
        "x1 = e1(torch.tensor([(df_numpy[:,3])],dtype=torch.long))\n",
        "x2 = e1(torch.tensor([(df_numpy[:,5])],dtype=torch.long))\n",
        "x = torch.cat([x1,x2],2)\n",
        "print(x1)\n",
        "print(x2)\n",
        "print(x)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-752edad2a8dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0me2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_numpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_numpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embs' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_oIE62A5lsv1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize weight of Embedding matrix\n",
        "def emb_init(x):\n",
        "    x = x.weight.data\n",
        "    sc = 2/(x.size(1)+1)\n",
        "    x.uniform_(-sc,sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ho91lBO2eWg0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size,emb_szs,hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
        "        for emb in embs: emb_init(emb)\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, input_cat):\n",
        "        x_torch = [e(input_cat[:,i]) for i,e in enumerate(self.embs)]\n",
        "        x = torch.cat(x_torch, 1)\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yBgwh5AseWea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j1mpYlaTeWbW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q1gdXgYiXacu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMEpkKLhXKZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "e71cf2bd-4777-41d5-ef8e-85e87bb045a1"
      },
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "logreg.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = logreg.predict(X_test)\n",
        "\n",
        "logreg.score(X_train, Y_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ba4e2f2bfb0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m-> 1216\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'male'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "WSI7ncntXI3u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": test_df[\"PassengerId\"],\n",
        "        \"Survived\": Y_pred\n",
        "    })\n",
        "submission.to_csv('titanic.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7CnWMlb-ea7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b98f542-5044-4d53-d17d-3511a3644480"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 columns were label encoded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M3lMdtgK_8MP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "19604d58-23bc-43ca-df01-b0d2ccde6d15"
      },
      "cell_type": "code",
      "source": [
        "# one-hot encoding of categorical variables\n",
        "app_train = pd.get_dummies(app_train)\n",
        "app_test = pd.get_dummies(app_test)\n",
        "\n",
        "print('Training Features shape: ', app_train.shape)\n",
        "print('Testing Features shape: ', app_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Features shape:  (307511, 243)\n",
            "Testing Features shape:  (48744, 239)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GPYznHefAAht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13a8a0a4-e117-4690-9edb-eecd4a71dd4c"
      },
      "cell_type": "code",
      "source": [
        "train_labels = app_train['TARGET']\n",
        "\n",
        "# Align the training and testing data, keep only columns present in both dataframes\n",
        "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
        "\n",
        "print('Training Features shape: ', app_train.shape)\n",
        "print('Testing Features shape: ', app_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Features shape:  (307511, 239)\n",
            "Testing Features shape:  (48744, 239)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pf9q2HQtIoEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03d5da05-13ea-4571-8b3f-0c881e1f2b9f"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
        "\n",
        "# Drop the target from the training data\n",
        "if 'TARGET' in app_train:\n",
        "    train = app_train.drop(columns = ['TARGET'])\n",
        "else:\n",
        "    train = app_train.copy()\n",
        "features = list(train.columns)\n",
        "\n",
        "# Copy of the testing data\n",
        "test = app_test.copy()\n",
        "\n",
        "# Median imputation of missing values\n",
        "imputer = Imputer(strategy = 'median')\n",
        "\n",
        "# Scale each feature to 0-1\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "\n",
        "# Fit on the training data\n",
        "imputer.fit(train)\n",
        "\n",
        "# Transform both training and testing data\n",
        "train = imputer.transform(train)\n",
        "test = imputer.transform(app_test)\n",
        "\n",
        "# Repeat with the scaler\n",
        "scaler.fit(train)\n",
        "train = scaler.transform(train)\n",
        "test = scaler.transform(test)\n",
        "\n",
        "print('Training data shape: ', train.shape)\n",
        "print('Testing data shape: ', test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape:  (307511, 239)\n",
            "Testing data shape:  (48744, 239)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XfAraOTHJKwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "285c6870-1774-4cfd-ee5a-e42f7b31beee"
      },
      "cell_type": "code",
      "source": [
        "val = train[246009:]\n",
        "train = train[:246009]\n",
        "print(train.shape)\n",
        "print(val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(246009, 239)\n",
            "(61502, 239)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j5m_QVLbO7Ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0470ea9-cf97-4621-cdcf-6c454e0a5a55"
      },
      "cell_type": "code",
      "source": [
        "print(val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 239)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sFfCr-DLL38K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "a6a935e4-4333-414f-d11a-6c217a02f5f1"
      },
      "cell_type": "code",
      "source": [
        "train_label = train_labels[:246009] #80% Need to randomize / Highly imbalanced\n",
        "val_label = train_labels[246009:] \n",
        "print(train_label.shape)\n",
        "print(val_label.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(246009,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-60b724a162cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m246009\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_label' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UhQ4FKG9BNSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Split into Train / Validation - Not Now\n",
        "#train=app_train.sample(frac=0.8,random_state=200)\n",
        "#Validation=app_train.drop(train.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ubdFlCD9E-WE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4eb37ca2-c99d-42e2-ea33-ebf82b65508d"
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5bc06000 @  0x7fabc2bc21c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\r\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q0ni0th4EXNs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yUHuveajILG8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5qQPtbl7DucJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Logistic Regression for MNIST\n",
        "# Hyper-parameters \n",
        "input_size = 239\n",
        "num_classes = 2\n",
        "num_epochs = 5\n",
        "batch_size = 1000\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kO-NbjqVPFT3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_torch = torch.from_numpy(train)\n",
        "train_torch = train_torch.type(torch.float)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9XPQjvhUPkzu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_torch = torch.from_numpy(val)\n",
        "val_torch = val_torch.type(torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNbeQDVDRULI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_torch_label = train_label.astype('float32')\n",
        "val_torch_label = val_label.astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3FpOG6oS8Cp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#train_torch_label = torch.from_numpy(np.array(train_label.astype('int32')))\n",
        "#train_torch_label = train_torch_label.type(torch.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wTUeiHdpVfxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d207e642-2c51-4c71-c472-48c0c85de41b"
      },
      "cell_type": "code",
      "source": [
        "shape_check = np.array(train_label.values.reshape(-1,1))\n",
        "print(shape_check.shape)\n",
        "print(shape_check.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(246009, 1)\n",
            "int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ccmf79hYWXZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_torch_label = torch.from_numpy(shape_check)\n",
        "#train_torch_label = train_torch_label.type(torch.FloatTensor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N3G8n98qSN2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e39313d2-d95f-4efc-b01d-0dddbf9c6392"
      },
      "cell_type": "code",
      "source": [
        "shape_check_en = np.array(train_label.values.reshape(-1))\n",
        "print(shape_check_en.shape)\n",
        "train_torch_label = torch.from_numpy(shape_check_en)\n",
        "train_torch_label = train_torch_label.type(torch.LongTensor) #Entropy Loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(246009,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GEbpGXjLSwVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "254c888c-7d3d-451d-c3aa-2ec20c4c5612"
      },
      "cell_type": "code",
      "source": [
        "train_torch_label[1:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  1,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,\n",
              "         0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "KOC8Vo0ZVF2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b05dc97b-4da7-4d03-d5ef-dcdbfe5e74ac"
      },
      "cell_type": "code",
      "source": [
        "print(train_torch_label.shape)\n",
        "print(train_torch.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([246009, 1])\n",
            "torch.Size([246009, 239])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aPioZOL3E2at",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "09c8ed0b-16c3-403c-d513-e5f3d3c3e20f"
      },
      "cell_type": "code",
      "source": [
        "model = nn.Linear(input_size,2) # We try to predict the value on output (eg: House price ) with four given feature (room size, etc..)\n",
        "#criterion = nn.BCEWithLogitsLoss()\n",
        "criterion = nn.CrossEntropyLoss()  #- Not working need to know why \n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=.001) # linear parameters are w, b which we get using linear.weight , linear.bias\n",
        "#print ('Weight & Bias Before Training ',model.weight,'&', model.bias)\n",
        "for epoch in range(1000):\n",
        "  # Forward_pass\n",
        "  pred = model(train_torch) # give the data to calculate forward linear layer\n",
        "\n",
        "  loss = criterion(pred,train_torch_label) # compare prediction vs actuals\n",
        "  if (epoch + 1) % 10 == 0 :\n",
        "    print ('Epoch : loss ' , epoch, loss.item())\n",
        "\n",
        "  # Make gradient to be zero\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Backward pass  Auto differntiation not much of an worry\n",
        "  loss.backward()\n",
        "\n",
        "  #Update using optimizer after calculating loss\n",
        "  optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : loss  9 0.7202233672142029\n",
            "Epoch : loss  19 0.656916081905365\n",
            "Epoch : loss  29 0.6042614579200745\n",
            "Epoch : loss  39 0.5603563189506531\n",
            "Epoch : loss  49 0.523647665977478\n",
            "Epoch : loss  59 0.49281832575798035\n",
            "Epoch : loss  69 0.4667985439300537\n",
            "Epoch : loss  79 0.44472846388816833\n",
            "Epoch : loss  89 0.4259069859981537\n",
            "Epoch : loss  99 0.4097803235054016\n",
            "Epoch : loss  109 0.39588966965675354\n",
            "Epoch : loss  119 0.3838669955730438\n",
            "Epoch : loss  129 0.373418927192688\n",
            "Epoch : loss  139 0.36429110169410706\n",
            "Epoch : loss  149 0.35629841685295105\n",
            "Epoch : loss  159 0.34924760460853577\n",
            "Epoch : loss  169 0.34302955865859985\n",
            "Epoch : loss  179 0.337514191865921\n",
            "Epoch : loss  189 0.3326060473918915\n",
            "Epoch : loss  199 0.32822930812835693\n",
            "Epoch : loss  209 0.32431474328041077\n",
            "Epoch : loss  219 0.32080078125\n",
            "Epoch : loss  229 0.3176402747631073\n",
            "Epoch : loss  239 0.31479012966156006\n",
            "Epoch : loss  249 0.31221550703048706\n",
            "Epoch : loss  259 0.3098870813846588\n",
            "Epoch : loss  269 0.3077670931816101\n",
            "Epoch : loss  279 0.30584242939949036\n",
            "Epoch : loss  289 0.3040943145751953\n",
            "Epoch : loss  299 0.3024941682815552\n",
            "Epoch : loss  309 0.3010302484035492\n",
            "Epoch : loss  319 0.299690306186676\n",
            "Epoch : loss  329 0.2984620928764343\n",
            "Epoch : loss  339 0.2973388135433197\n",
            "Epoch : loss  349 0.2963007092475891\n",
            "Epoch : loss  359 0.29534783959388733\n",
            "Epoch : loss  369 0.2944687604904175\n",
            "Epoch : loss  379 0.2936602830886841\n",
            "Epoch : loss  389 0.2929108440876007\n",
            "Epoch : loss  399 0.2922075390815735\n",
            "Epoch : loss  409 0.29157382249832153\n",
            "Epoch : loss  419 0.2909772992134094\n",
            "Epoch : loss  429 0.29042571783065796\n",
            "Epoch : loss  439 0.2899099886417389\n",
            "Epoch : loss  449 0.2894282937049866\n",
            "Epoch : loss  459 0.2889890670776367\n",
            "Epoch : loss  469 0.2885796129703522\n",
            "Epoch : loss  479 0.28818655014038086\n",
            "Epoch : loss  489 0.28782758116722107\n",
            "Epoch : loss  499 0.28749147057533264\n",
            "Epoch : loss  509 0.28717294335365295\n",
            "Epoch : loss  519 0.28688836097717285\n",
            "Epoch : loss  529 0.2866109311580658\n",
            "Epoch : loss  539 0.2863512933254242\n",
            "Epoch : loss  549 0.286105215549469\n",
            "Epoch : loss  559 0.2858771085739136\n",
            "Epoch : loss  569 0.2856631875038147\n",
            "Epoch : loss  579 0.2854643166065216\n",
            "Epoch : loss  589 0.2852798104286194\n",
            "Epoch : loss  599 0.28510117530822754\n",
            "Epoch : loss  609 0.2849358022212982\n",
            "Epoch : loss  619 0.28477486968040466\n",
            "Epoch : loss  629 0.2846245765686035\n",
            "Epoch : loss  639 0.28448542952537537\n",
            "Epoch : loss  649 0.28435197472572327\n",
            "Epoch : loss  659 0.2842229902744293\n",
            "Epoch : loss  669 0.28410544991493225\n",
            "Epoch : loss  679 0.28399136662483215\n",
            "Epoch : loss  689 0.2838841378688812\n",
            "Epoch : loss  699 0.2837834060192108\n",
            "Epoch : loss  709 0.28368839621543884\n",
            "Epoch : loss  719 0.2835983633995056\n",
            "Epoch : loss  729 0.28350943326950073\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch : loss  739 0.2834256887435913\n",
            "Epoch : loss  749 0.28334590792655945\n",
            "Epoch : loss  759 0.28326845169067383\n",
            "Epoch : loss  769 0.28320080041885376\n",
            "Epoch : loss  779 0.2831307649612427\n",
            "Epoch : loss  789 0.2830653786659241\n",
            "Epoch : loss  799 0.2829993665218353\n",
            "Epoch : loss  809 0.282941073179245\n",
            "Epoch : loss  819 0.2828829884529114\n",
            "Epoch : loss  829 0.28282636404037476\n",
            "Epoch : loss  839 0.28277233242988586\n",
            "Epoch : loss  849 0.28271737694740295\n",
            "Epoch : loss  859 0.28267261385917664\n",
            "Epoch : loss  869 0.28262361884117126\n",
            "Epoch : loss  879 0.282578706741333\n",
            "Epoch : loss  889 0.2825348377227783\n",
            "Epoch : loss  899 0.2824908494949341\n",
            "Epoch : loss  909 0.2824496328830719\n",
            "Epoch : loss  919 0.2824104130268097\n",
            "Epoch : loss  929 0.2823731303215027\n",
            "Epoch : loss  939 0.2823340892791748\n",
            "Epoch : loss  949 0.28229907155036926\n",
            "Epoch : loss  959 0.28226059675216675\n",
            "Epoch : loss  969 0.28222551941871643\n",
            "Epoch : loss  979 0.28219348192214966\n",
            "Epoch : loss  989 0.2821611166000366\n",
            "Epoch : loss  999 0.28213241696357727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NqEHbEH3MTVv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shape_check_1 = np.array(val_label.values.reshape(-1,1))\n",
        "val_torch_label = torch.from_numpy(shape_check_1)\n",
        "val_torch_label = val_torch_label.type(torch.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GsGKGbVkN6mR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de8d4f55-6aeb-4c4f-8001-9c1d90fb7497"
      },
      "cell_type": "code",
      "source": [
        "print(len(val_torch_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GkhD3XK2Otvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25c78711-0560-4f79-8662-176e84ec10f6"
      },
      "cell_type": "code",
      "source": [
        "val_torch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "e7_7vrp7Onut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "outputs = model(val_torch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6F1k2bnPqLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1700
        },
        "outputId": "daf0f41c-08d5-40e2-c5ea-7c3fea4aacf3"
      },
      "cell_type": "code",
      "source": [
        "outputs.data[1:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.3158, -1.0888],\n",
              "        [ 1.2086, -1.4148],\n",
              "        [ 1.1513, -1.4100],\n",
              "        [ 0.9837, -1.2315],\n",
              "        [ 0.9273, -1.2824],\n",
              "        [ 1.1998, -1.4108],\n",
              "        [ 1.1628, -1.4402],\n",
              "        [ 1.0884, -1.2363],\n",
              "        [ 1.2043, -1.1194],\n",
              "        [ 1.1667, -1.1946],\n",
              "        [ 0.9191, -1.3910],\n",
              "        [ 1.3064, -1.0397],\n",
              "        [ 0.9005, -1.5179],\n",
              "        [ 1.3576, -1.0511],\n",
              "        [ 1.3109, -1.1683],\n",
              "        [ 0.9735, -1.2716],\n",
              "        [ 0.9415, -1.1160],\n",
              "        [ 1.1832, -1.4745],\n",
              "        [ 1.0139, -1.0569],\n",
              "        [ 1.1154, -1.2072],\n",
              "        [ 1.0687, -1.0962],\n",
              "        [ 1.0566, -1.1157],\n",
              "        [ 1.0747, -1.1220],\n",
              "        [ 1.0723, -1.2843],\n",
              "        [ 1.1602, -1.0342],\n",
              "        [ 1.1457, -1.1542],\n",
              "        [ 1.1119, -1.1272],\n",
              "        [ 1.1443, -1.3893],\n",
              "        [ 1.1321, -1.1698],\n",
              "        [ 1.1718, -1.1324],\n",
              "        [ 1.2228, -1.1434],\n",
              "        [ 1.0078, -1.0492],\n",
              "        [ 0.9604, -1.1373],\n",
              "        [ 1.1994, -1.2910],\n",
              "        [ 1.0849, -1.4739],\n",
              "        [ 0.9986, -1.3694],\n",
              "        [ 1.0268, -1.3813],\n",
              "        [ 1.0987, -1.2673],\n",
              "        [ 1.1686, -1.2997],\n",
              "        [ 1.1056, -1.3197],\n",
              "        [ 1.1618, -1.2069],\n",
              "        [ 1.2685, -0.9794],\n",
              "        [ 0.9469, -1.2588],\n",
              "        [ 1.2225, -1.1632],\n",
              "        [ 1.1574, -1.4480],\n",
              "        [ 1.3090, -1.1260],\n",
              "        [ 1.0938, -1.4843],\n",
              "        [ 1.2439, -1.3240],\n",
              "        [ 0.9560, -1.2383],\n",
              "        [ 1.5330, -1.3525],\n",
              "        [ 1.1922, -1.0040],\n",
              "        [ 1.1809, -1.4352],\n",
              "        [ 1.3401, -1.0369],\n",
              "        [ 1.2138, -0.9315],\n",
              "        [ 1.0997, -1.0611],\n",
              "        [ 1.0198, -1.0715],\n",
              "        [ 1.0782, -1.2490],\n",
              "        [ 1.1281, -1.1869],\n",
              "        [ 1.1717, -1.1912],\n",
              "        [ 1.0214, -1.4568],\n",
              "        [ 1.2713, -1.0641],\n",
              "        [ 1.0202, -1.3433],\n",
              "        [ 1.0319, -1.1838],\n",
              "        [ 1.4132, -1.1469],\n",
              "        [ 1.4470, -1.2606],\n",
              "        [ 1.1155, -1.3089],\n",
              "        [ 1.1309, -1.1747],\n",
              "        [ 1.1261, -1.2887],\n",
              "        [ 1.1493, -1.2142],\n",
              "        [ 1.2427, -1.1704],\n",
              "        [ 1.0721, -1.2951],\n",
              "        [ 1.0933, -1.4343],\n",
              "        [ 0.9727, -1.3197],\n",
              "        [ 1.2852, -1.4059],\n",
              "        [ 1.1075, -1.0960],\n",
              "        [ 1.2035, -1.3552],\n",
              "        [ 1.1615, -1.2508],\n",
              "        [ 1.2457, -1.1187],\n",
              "        [ 1.1773, -1.1104],\n",
              "        [ 1.0331, -1.1547],\n",
              "        [ 1.3021, -1.2615],\n",
              "        [ 0.9889, -1.2412],\n",
              "        [ 1.2504, -1.4474],\n",
              "        [ 1.2825, -1.1012],\n",
              "        [ 1.0348, -1.3156],\n",
              "        [ 1.2879, -1.1205],\n",
              "        [ 1.1340, -1.1404],\n",
              "        [ 1.0179, -1.1694],\n",
              "        [ 1.1150, -1.1525],\n",
              "        [ 0.9566, -1.2742],\n",
              "        [ 0.9976, -1.1744],\n",
              "        [ 1.0772, -1.3224],\n",
              "        [ 1.3098, -1.4174],\n",
              "        [ 1.1828, -1.0319],\n",
              "        [ 1.2744, -0.9787],\n",
              "        [ 1.2456, -1.2733],\n",
              "        [ 0.8971, -1.2791],\n",
              "        [ 1.2194, -0.9128],\n",
              "        [ 1.1538, -1.2365]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "eldlX_lGUm1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs.data, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O8ShaCGpUrcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "df008e64-8274-4d23-d729-77283a231427"
      },
      "cell_type": "code",
      "source": [
        "predicted[1:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "z4K6PxJwXGCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "653643fb-027c-49ee-e0b1-ef2fbfe6ee35"
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 61502\n",
        "    outputs = model(val_torch)\n",
        "    for i in range(len(val_torch_label)):\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += (predicted[i] == val_torch_label[i].type(torch.LongTensor)).sum()\n",
        "      \n",
        "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images: 92 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0M2oc6yhXGP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#_, predicted = torch.max(outputs.data, 1)\n",
        "y_pred = predicted.detach().numpy()\n",
        "y = val_torch_label.type(torch.LongTensor).detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSuXL9cnYGRZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbPlQd1uYTSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bf2f362-2c47-4f4c-d873-5510b7bbae65"
      },
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61502,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "metadata": {
        "id": "khglG4BbX2hd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0e3a264c-436e-4c6d-8d95-8e4448f3ece5"
      },
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(y, y_pred, pos_label=2)\n",
        "metrics.auc(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:571: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "FU0RogKdXXPn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aucmeter = AUCMeter()\n",
        "aucmeter.add(y_pred, y)\n",
        "print(aucmeter.value()[0], sklearn.metrics.roc_auc_score(y_true,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}